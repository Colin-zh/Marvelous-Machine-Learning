{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>模型验证及优化<span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型验证优化主要包括确定评估指标、交叉验证、模型比较、验证结果可视化分析、结果分析和模型调参。<br/>\n",
    "一般模型选择调优的步骤为：评价指标->验证方式->学习曲线->结果分析->模型选择->模型调参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "#########部分SKLearn 集成的算法###############\n",
    "from sklearn import metrics  \n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns',10)  \n",
    "pd.set_option('display.max_rows',20) \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "############全局参数#################################\n",
    "id_col_names=['user_id','coupon_id','date_received']\n",
    "target_col_name='label'\n",
    "id_target_cols=['user_id','coupon_id','date_received','label']\n",
    "myeval='roc_auc'\n",
    "#cvscore=0\n",
    "\n",
    "############目录定义#################################\n",
    "datapath = '../data/' \n",
    "featurepath = '../feature/' \n",
    "resultpath = '../result/'\n",
    "tmppath = '../tmp/'\n",
    "scorepath = '../score/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########工具函数#############################################\n",
    "#返回ID列\n",
    "def get_id_df(df):\n",
    "    return df[id_col_names]\n",
    "\n",
    "\n",
    "#返回Target列\n",
    "def get_target_df(df):\n",
    "    return df[target_col_name]\n",
    "\n",
    "\n",
    "#返回特征列\n",
    "def get_predictors_df(df):\n",
    "    predictors = [f for f in df.columns if f not in id_target_cols]\n",
    "    return df[predictors]\n",
    "\n",
    "\n",
    "#按特征名读取训练集\n",
    "def read_featurefile_train(featurename):\n",
    "    df = pd.read_csv(featurepath + 'train_' + featurename + '.csv',\n",
    "                     sep=',',\n",
    "                     encoding=\"utf-8\")\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#按特征名读取测试集\n",
    "def read_featurefile_test(featurename):\n",
    "    df = pd.read_csv(featurepath + 'test_' + featurename + '.csv',\n",
    "                     sep=',',\n",
    "                     encoding=\"utf-8\")\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 将特征归一化\n",
    "def standize_df(train_data, test_data):\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    features_columns = [\n",
    "        f for f in test_data.columns if f not in id_target_cols\n",
    "    ]\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    train_data_scaler = min_max_scaler.fit_transform(train_data[features_columns])\n",
    "    test_data_scaler = min_max_scaler.fit_transform(test_data[features_columns])\n",
    "\n",
    "    train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "    train_data_scaler.columns = features_columns\n",
    "\n",
    "    test_data_scaler = pd.DataFrame(test_data_scaler)\n",
    "    test_data_scaler.columns = features_columns\n",
    "\n",
    "    train_data_scaler['label'] = train_data['label']\n",
    "    train_data_scaler[id_col_names] = train_data[id_col_names]\n",
    "    test_data_scaler[id_col_names] = test_data[id_col_names]\n",
    "    return train_data_scaler, test_data_scaler\n",
    "\n",
    "\n",
    "#按特征名读取数据\n",
    "def read_data(featurename):\n",
    "    traindf = read_featurefile_train(featurename)\n",
    "    testdf = read_featurefile_test(featurename)\n",
    "    #return traindf,testdf\n",
    "    return standize_df(traindf, testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据读取\n",
    "#所有的特征都是上一节生成的\n",
    "train_f1, test_f1 = read_data('f1')\n",
    "#所有的特征都是上一节生成的\n",
    "train_f2, test_f2 = read_data('sf2')\n",
    "#所有的特征都是上一节生成的\n",
    "train_f3, test_f3 = read_data('sf3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价指标及预测方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#性能评价函数\n",
    "#本赛题目标是预测投放的优惠券是否核销。\n",
    "#针对此任务及一些相关背景知识，使用优惠券核销预测的平均AUC（ROC曲线下面积）作为评价标准。\n",
    "#即对每个优惠券coupon_id单独计算核销预测的AUC值，再对所有优惠券的AUC值求平均作为最终的评价标准。\n",
    "# coupon平均auc计算\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def myauc(test):\n",
    "    testgroup = test.groupby(['coupon_id'])\n",
    "    aucs = []\n",
    "    for i in testgroup:\n",
    "        coupon_df = i[1]\n",
    "        #测算AUC必须大于1个类别\n",
    "        if len(coupon_df['label'].unique()) < 2:\n",
    "            continue\n",
    "        auc = metrics.roc_auc_score(coupon_df['label'], coupon_df['pred'])\n",
    "        aucs.append(auc)\n",
    "    return np.average(aucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然赛题是按照coupon的AUC来计算。不过因为整体AUC（也就是用roc_auc_score 求出的结果）与Coupon AUC同增同减，所以在进行评估的时候可以直接使用整体AUC。<br/>\n",
    "预测方式，因为要的结果是购买的几率，所以不能直接用Predict因为这样会直接返回0,1,而要用predict_proba，它会返回每个类别的可能行，取其中为1的列即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证方式\n",
    "### 简单交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train 总体AUC:    0.664855500345236\n",
      "LogisticRegression test 总体AUC:    0.6630928317399557\n",
      "LogisticRegression train Coupon AUC:    0.5371297140333575\n",
      "LogisticRegression test Coupon AUC:    0.5538079214049014\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证F1（随机抽样）\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "target = get_target_df(train_f1).copy()\n",
    "traindf = train_f1.copy()\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_all, test_all, train_target, test_target = train_test_split(\n",
    "    traindf, target, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = get_predictors_df(train_all).copy()\n",
    "test_data = get_predictors_df(test_all).copy()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_target)\n",
    "train_pred = clf.predict_proba(train_data)[:, 1]\n",
    "test_pred = clf.predict_proba(test_data)[:, 1]\n",
    "\n",
    "score_train = metrics.roc_auc_score(train_target, train_pred)\n",
    "score_test = metrics.roc_auc_score(test_target, test_pred)\n",
    "print(\"LogisticRegression train 总体AUC:   \", score_train)\n",
    "print(\"LogisticRegression test 总体AUC:   \", score_test)\n",
    "\n",
    "train_all['pred'] = train_pred\n",
    "test_all['pred'] = test_pred\n",
    "print(\"LogisticRegression train Coupon AUC:   \", myauc(train_all))\n",
    "print(\"LogisticRegression test Coupon AUC:   \", myauc(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09203348015451115\n",
      "0.08961938852582838\n"
     ]
    }
   ],
   "source": [
    "print(train_target.sum()/train_target.count())\n",
    "print(test_target.sum()/test_target.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train 总体AUC:    0.8397681496604559\n",
      "LogisticRegression test 总体AUC:    0.8426368250072935\n",
      "LogisticRegression train Coupon AUC:    0.7164199492560941\n",
      "LogisticRegression test Coupon AUC:    0.7271008836459031\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证F3（随机抽样）\n",
    "from sklearn.model_selection import train_test_split  # 切分数据\n",
    "\n",
    "target = get_target_df(train_f3).copy()\n",
    "traindf = train_f3.copy()\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "train_all, test_all, train_target, test_target = train_test_split(\n",
    "    traindf, target, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = get_predictors_df(train_all).copy()\n",
    "test_data = get_predictors_df(test_all).copy()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_target)\n",
    "train_pred = clf.predict_proba(train_data)[:, 1]\n",
    "test_pred = clf.predict_proba(test_data)[:, 1]\n",
    "\n",
    "score_train = roc_auc_score(train_target, train_pred)\n",
    "score_test = roc_auc_score(test_target, test_pred)\n",
    "print(\"LogisticRegression train 总体AUC:   \", score_train)\n",
    "print(\"LogisticRegression test 总体AUC:   \", score_test)\n",
    "\n",
    "train_all['pred'] = train_pred\n",
    "test_all['pred'] = test_pred\n",
    "print(\"LogisticRegression train Coupon AUC:   \", myauc(train_all))\n",
    "print(\"LogisticRegression test Coupon AUC:   \", myauc(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07603585407323725\n",
      "0.07786932012689139\n"
     ]
    }
   ],
   "source": [
    "print(train_target.sum()/train_target.count())\n",
    "print(test_target.sum()/test_target.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：上面的结果最终都是test的AUC要高于train的AUC，可能原因有：<br/>\n",
    "（1）数据集太小的话，如果数据集切分的不均匀，或者说训练集和测试集的分布不均匀，如果模型能够正确捕捉到数据内部的分布模式话，这可能造成训练集的内部方差大于验证集，会造成训练集的误差更大。这时你要重新切分数据集或者扩充数据集，使其分布一样。<br/>\n",
    "（2）模型正则化过多，比如训练时dropout过多，和验证时的模型相差较大，验证时是不会有dropout的。<br/>\n",
    "（3）训练的精度是每个batch产生的，而验证的精度一般是一个epoch后产生的，验证时的模型是训练一个个batch之后的，有一个的滞后性；可以说训练得差不多的模型用来验证，当然精度要高一点。\n",
    "\n",
    "上述主要是由于样本分布不均匀导致的：<br/>\n",
    "采用纯随机的采样方式，这种方式对于大量数据集以及对于目标值分布均匀的情况是可行的。对于分类任务，我们训练一个二值分类器，可能数据中包含大量的正例样本，仅仅包含10%的反例样本，此时的标签分布很不均匀，如果我们通过随机采样的方式，极端情况下可能将正例样本都划分到训练集上，而反例样本恰好都分到测试集，这样训练出来的模型，效果一定不会太好，所以我们需要采用分层采样的方式进行划分数据集，也就是说保证训练集中既包含一定比例的正例样本又要包含一定比例的负例样本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train 总体AUC:    0.664308887617256\n",
      "LogisticRegression test 总体AUC:    0.6638601261747832\n",
      "LogisticRegression train Coupon AUC:    0.5394647995244093\n",
      "LogisticRegression test Coupon AUC:    0.5400207956095779\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证F1（分层随机抽样）\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # 切分数据\n",
    "\n",
    "target = get_target_df(train_f1).copy()\n",
    "traindf = train_f1.copy()\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(traindf, target):\n",
    "    train_all = traindf.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    test_all = traindf.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "\n",
    "train_data = get_predictors_df(train_all).copy()\n",
    "test_data = get_predictors_df(test_all).copy()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_target)\n",
    "train_pred = clf.predict_proba(train_data)[:, 1]\n",
    "test_pred = clf.predict_proba(test_data)[:, 1]\n",
    "\n",
    "score_train = metrics.roc_auc_score(train_target, train_pred)\n",
    "score_test = metrics.roc_auc_score(test_target, test_pred)\n",
    "print(\"LogisticRegression train 总体AUC:   \", score_train)\n",
    "print(\"LogisticRegression test 总体AUC:   \", score_test)\n",
    "\n",
    "train_all['pred'] = train_pred\n",
    "test_all['pred'] = test_pred\n",
    "print(\"LogisticRegression train Coupon AUC:   \", myauc(train_all))\n",
    "print(\"LogisticRegression test Coupon AUC:   \", myauc(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09154909341685584\n",
      "0.09155692752290565\n"
     ]
    }
   ],
   "source": [
    "print(train_target.sum()/train_target.count())\n",
    "print(test_target.sum()/test_target.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train 总体AUC:    0.8401624524510642\n",
      "LogisticRegression test 总体AUC:    0.8392721490135375\n",
      "LogisticRegression train Coupon AUC:    0.7171906886469563\n",
      "LogisticRegression test Coupon AUC:    0.7315922306904856\n"
     ]
    }
   ],
   "source": [
    "# 简单交叉验证F3（分层随机抽样）\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # 切分数据\n",
    "\n",
    "target = get_target_df(train_f3).copy()\n",
    "traindf = train_f3.copy()\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(traindf, target):\n",
    "    train_all = traindf.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    test_all = traindf.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "\n",
    "train_data = get_predictors_df(train_all).copy()\n",
    "test_data = get_predictors_df(test_all).copy()\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_data, train_target)\n",
    "train_pred = clf.predict_proba(train_data)[:, 1]\n",
    "test_pred = clf.predict_proba(test_data)[:, 1]\n",
    "\n",
    "score_train = metrics.roc_auc_score(train_target, train_pred)\n",
    "score_test = metrics.roc_auc_score(test_target, test_pred)\n",
    "print(\"LogisticRegression train 总体AUC:   \", score_train)\n",
    "print(\"LogisticRegression test 总体AUC:   \", score_test)\n",
    "\n",
    "train_all['pred'] = train_pred\n",
    "test_all['pred'] = test_pred\n",
    "print(\"LogisticRegression train Coupon AUC:   \", myauc(train_all))\n",
    "print(\"LogisticRegression test Coupon AUC:   \", myauc(test_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07640386612349229\n",
      "0.07639728872355478\n"
     ]
    }
   ],
   "source": [
    "print(train_target.sum()/train_target.count())\n",
    "print(test_target.sum()/test_target.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K折交叉验证 K-fold CV\n",
    "K折交叉验证： KFold 将所有的样例划分为 k 个组，称为折叠 (fold) （如果 k = n， 这等价于 Leave One Out（留一） 策略），都具有相同的大小（如果可能）。预测函数学习时使用 k - 1 个折叠中的数据，最后一个剩下的折叠会用于测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  折 LogisticRegression train 总体AUC:    0.8330477476356697\n",
      "1  折 LogisticRegression test 总体AUC:    0.8683972587488785\n",
      "1  折 LogisticRegression train Coupon AUC:    0.7114559568788156\n",
      "1  折 LogisticRegression test Coupon AUC:    0.7251598500317984 \n",
      "\n",
      "2  折 LogisticRegression train 总体AUC:    0.8331516430725072\n",
      "2  折 LogisticRegression test 总体AUC:    0.8649730424625975\n",
      "2  折 LogisticRegression train Coupon AUC:    0.7145694335559735\n",
      "2  折 LogisticRegression test Coupon AUC:    0.7162330353981553 \n",
      "\n",
      "3  折 LogisticRegression train 总体AUC:    0.84433185047919\n",
      "3  折 LogisticRegression test 总体AUC:    0.8209095516363233\n",
      "3  折 LogisticRegression train Coupon AUC:    0.720120242277777\n",
      "3  折 LogisticRegression test Coupon AUC:    0.7228972032906389 \n",
      "\n",
      "4  折 LogisticRegression train 总体AUC:    0.8454061094994901\n",
      "4  折 LogisticRegression test 总体AUC:    0.8168713267119359\n",
      "4  折 LogisticRegression train Coupon AUC:    0.7097917580768762\n",
      "4  折 LogisticRegression test Coupon AUC:    0.7415823871476624 \n",
      "\n",
      "5  折 LogisticRegression train 总体AUC:    0.8456448838657696\n",
      "5  折 LogisticRegression test 总体AUC:    0.8161159483951848\n",
      "5  折 LogisticRegression train Coupon AUC:    0.7126500182611298\n",
      "5  折 LogisticRegression test Coupon AUC:    0.7294278810414 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "train = train_f3.copy()\n",
    "target = get_target_df(train_f3).copy()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    train_data, test_data, train_target, test_target = train.iloc[\n",
    "        train_index], train.iloc[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(get_predictors_df(train_data), train_target)\n",
    "\n",
    "    train_pred = clf.predict_proba(get_predictors_df(train_data))[:, 1]\n",
    "    test_pred = clf.predict_proba(get_predictors_df(test_data))[:, 1]\n",
    "    score_train = roc_auc_score(train_target, train_pred)\n",
    "    score_test = roc_auc_score(test_target, test_pred)\n",
    "    train_data['pred'] = train_pred\n",
    "    test_data['pred'] = test_pred\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train 总体AUC:   \", score_train)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test 总体AUC:   \", score_test)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train Coupon AUC:   \", myauc(train_data))\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test Coupon AUC:   \", myauc(test_data), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 留P法 LPO CV\n",
    "留一交叉验证： LeaveOneOut (或 LOO) 是一个简单的交叉验证。每个学习集都是通过除了一个样本以外的所有样本创建的，测试集是被留下的样本。 因此，对于 n 个样本，我们有 n 个不同的训练集和 n 个不同的测试集。这种交叉验证程序不会浪费太多数据，因为只有一个样本是从训练集中删除掉的<br/>\n",
    "\n",
    "留P交叉验证： LeavePOut 与 LeaveOneOut 非常相似，因为它通过从整个集合中删除 p 个样本来创建所有可能的 训练/测试集。对于 n 个样本，这产生了 {n \\choose p} 个 训练-测试 对。**LeaveOneOut 和 KFold 不同，当 p > 1 时，测试集会重叠**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  折 LogisticRegression train 总体AUC:    0.840155111392265\n",
      "1  折 LogisticRegression test 总体AUC:    0.8765514184397163\n",
      "1  折 LogisticRegression train Coupon AUC:    0.7128813242218235\n",
      "1  折 LogisticRegression test Coupon AUC:    0.6578947368421053 \n",
      "\n",
      "2  折 LogisticRegression train 总体AUC:    0.8402230671740365\n",
      "2  折 LogisticRegression test 总体AUC:    0.8778812056737588\n",
      "2  折 LogisticRegression train Coupon AUC:    0.7130975302589041\n",
      "2  折 LogisticRegression test Coupon AUC:    0.675 \n",
      "\n",
      "3  折 LogisticRegression train 总体AUC:    0.8401036286962222\n",
      "3  折 LogisticRegression test 总体AUC:    0.8769946808510638\n",
      "3  折 LogisticRegression train Coupon AUC:    0.7124473896509698\n",
      "3  折 LogisticRegression test Coupon AUC:    0.631578947368421 \n",
      "\n",
      "4  折 LogisticRegression train 总体AUC:    0.8402346210132577\n",
      "4  折 LogisticRegression test 总体AUC:    0.8792109929078014\n",
      "4  折 LogisticRegression train Coupon AUC:    0.7131071670508777\n",
      "4  折 LogisticRegression test Coupon AUC:    0.6578947368421053 \n",
      "\n",
      "5  折 LogisticRegression train 总体AUC:    0.8401448557347355\n",
      "5  折 LogisticRegression test 总体AUC:    0.8743351063829787\n",
      "5  折 LogisticRegression train Coupon AUC:    0.7125603923092174\n",
      "5  折 LogisticRegression test Coupon AUC:    0.6578947368421053 \n",
      "\n",
      "6  折 LogisticRegression train 总体AUC:    0.8402998829184241\n",
      "6  折 LogisticRegression test 总体AUC:    0.8738918439716312\n",
      "6  折 LogisticRegression train Coupon AUC:    0.712649587725296\n",
      "6  折 LogisticRegression test Coupon AUC:    0.6578947368421053 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = train_f3.copy()\n",
    "target = get_target_df(train_f3).copy()\n",
    "\n",
    "from sklearn.model_selection import LeavePOut\n",
    "lpo = LeavePOut(p=200)\n",
    "num = 100\n",
    "for k, (train_index, test_index) in enumerate(lpo.split(train)):\n",
    "    train_data, test_data, train_target, test_target = train.iloc[\n",
    "        train_index], train.iloc[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(get_predictors_df(train_data), train_target)\n",
    "\n",
    "    train_pred = clf.predict_proba(get_predictors_df(train_data))[:, 1]\n",
    "    test_pred = clf.predict_proba(get_predictors_df(test_data))[:, 1]\n",
    "    score_train = roc_auc_score(train_target, train_pred)\n",
    "    score_test = roc_auc_score(test_target, test_pred)\n",
    "    train_data['pred'] = train_pred\n",
    "    test_data['pred'] = test_pred\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train 总体AUC:   \", score_train)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test 总体AUC:   \", score_test)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train Coupon AUC:   \",\n",
    "          myauc(train_data))\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test Coupon AUC:   \",\n",
    "          myauc(test_data), '\\n')\n",
    "    if k >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StratifiedKFold\n",
    "通过比较发现还是StratifiedKFold比较适合本赛题。因为本赛题正负样本分布不均匀。而StratifiedKFold 分层采样交叉切分，确保训练集，测试集中各类别样本的比例与原始数据集中相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  折 训练集正样本占比为  0.07640101331690116 测试集正样本占比为  0.07640869981970468\n",
      "1  折 LogisticRegression train 总体AUC:    0.8334219943143084\n",
      "1  折 LogisticRegression test 总体AUC:    0.8661577413429687\n",
      "1  折 LogisticRegression train Coupon AUC:    0.7153486555384969\n",
      "1  折 LogisticRegression test Coupon AUC:    0.7200170910771825 \n",
      "\n",
      "2  折 训练集正样本占比为  0.07640364815866124 测试集正样本占比为  0.07639816051031004\n",
      "2  折 LogisticRegression train 总体AUC:    0.8336627188196837\n",
      "2  折 LogisticRegression test 总体AUC:    0.8668170323937642\n",
      "2  折 LogisticRegression train Coupon AUC:    0.7114151037512919\n",
      "2  折 LogisticRegression test Coupon AUC:    0.7277546091351296 \n",
      "\n",
      "3  折 训练集正样本占比为  0.07640364815866124 测试集正样本占比为  0.07639816051031004\n",
      "3  折 LogisticRegression train 总体AUC:    0.8436483111789691\n",
      "3  折 LogisticRegression test 总体AUC:    0.8265614414455777\n",
      "3  折 LogisticRegression train Coupon AUC:    0.7158488232906889\n",
      "3  折 LogisticRegression test Coupon AUC:    0.7238334550841277 \n",
      "\n",
      "4  折 训练集正样本占比为  0.07640364815866124 测试集正样本占比为  0.07639816051031004\n",
      "4  折 LogisticRegression train 总体AUC:    0.8458804855827313\n",
      "4  折 LogisticRegression test 总体AUC:    0.8166089383162407\n",
      "4  折 LogisticRegression train Coupon AUC:    0.7136896454385652\n",
      "4  折 LogisticRegression test Coupon AUC:    0.7430500515779984 \n",
      "\n",
      "5  折 训练集正样本占比为  0.07640079536020859 测试集正样本占比为  0.07640957173667454\n",
      "5  折 LogisticRegression train 总体AUC:    0.8457364421084778\n",
      "5  折 LogisticRegression test 总体AUC:    0.8165094295651785\n",
      "5  折 LogisticRegression train Coupon AUC:    0.7136279485129962\n",
      "5  折 LogisticRegression test Coupon AUC:    0.7314453811856474 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5折交叉验证\n",
    "train = train_f3.copy()\n",
    "target = get_target_df(train_f3).copy()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    train_data, test_data, train_target, test_target = train.iloc[\n",
    "        train_index], train.iloc[test_index], target[train_index], target[\n",
    "            test_index]\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(get_predictors_df(train_data), train_target)\n",
    "\n",
    "    train_pred = clf.predict_proba(get_predictors_df(train_data))[:, 1]\n",
    "    test_pred = clf.predict_proba(get_predictors_df(test_data))[:, 1]\n",
    "    score_train = roc_auc_score(train_target, train_pred)\n",
    "    score_test = roc_auc_score(test_target, test_pred)\n",
    "    train_data['pred'] = train_pred\n",
    "    test_data['pred'] = test_pred\n",
    "    print(k + 1, \" 折\", \"训练集正样本占比为 \", train_target.sum()/train_target.count(), \n",
    "          \"测试集正样本占比为 \",test_target.sum()/test_target.count())\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train 总体AUC:   \", score_train)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test 总体AUC:   \", score_test)\n",
    "    print(k + 1, \" 折\", \"LogisticRegression train Coupon AUC:   \",\n",
    "          myauc(train_data))\n",
    "    print(k + 1, \" 折\", \"LogisticRegression test Coupon AUC:   \",\n",
    "          myauc(test_data), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型比较\n",
    "### 线下评测分数\n",
    "选定StratifiedKFold后我们可以直接用上面的方法对不同模型进行比对。也可以sklearn.model_selection.cross_val_score函数。它在cv是整数，而且目标是类别的时候也是用的StratifiedKFold。具体看：\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "不过本赛题因为评测指标是按Coupon的AUC，所以不能用它，要自己计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################使用sklearn的统一代码框架##########################\n",
    "#提供的函数包括：\n",
    "#classifier_single(featurename,classifier,cvnum)\n",
    "#按满减情况分别预测\n",
    "#classifier_single_sep_fd(featurename,classifier,cvnum):\n",
    "####################整合在sklearn的分类算法###############\n",
    "def get_sklearn_model(model_name, param=None):\n",
    "    #朴素贝叶斯\n",
    "    if model_name == 'NB':\n",
    "        model = MultinomialNB(alpha=0.01)\n",
    "    #逻辑回归\n",
    "    elif model_name == 'LR':\n",
    "        model = LogisticRegression(penalty='l2')\n",
    "    # KNN\n",
    "    elif model_name == 'KNN':\n",
    "        model = KNeighborsClassifier()\n",
    "    #随机森林\n",
    "    elif model_name == 'RF':\n",
    "        model = RandomForestClassifier()\n",
    "    #决策树\n",
    "    elif model_name == 'DT':\n",
    "        model = tree.DecisionTreeClassifier()\n",
    "    #向量机\n",
    "    elif model_name == 'SVC':\n",
    "        model = SVC(kernel='rbf')\n",
    "    #GBDT\n",
    "    elif model_name == 'GBDT':\n",
    "        model = GradientBoostingClassifier()\n",
    "    #XGBoost\n",
    "    elif model_name == 'XGB':\n",
    "        model = XGBClassifier()\n",
    "    #lightGBM\n",
    "    elif model_name == 'LGB':\n",
    "        model = LGBMClassifier()\n",
    "    else:\n",
    "        print(\"wrong model name!\")\n",
    "        return\n",
    "    if param is not None:\n",
    "        model.set_params(**param)\n",
    "    return model\n",
    "\n",
    "\n",
    "#对算法进行分析\n",
    "def classifier_df_score(train_feat, classifier, cvnum, param=None):\n",
    "    clf = get_sklearn_model(classifier, param)\n",
    "    train = train_feat.copy()\n",
    "    target = get_target_df(train_feat).copy()\n",
    "    kf = StratifiedKFold(n_splits=cvnum)\n",
    "\n",
    "    scores = []\n",
    "    score_coupons = []\n",
    "    for k, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "        train_data, test_data, train_target, test_target = train.iloc[\n",
    "            train_index], train.iloc[test_index], target[train_index], target[\n",
    "                test_index]\n",
    "        clf.fit(get_predictors_df(train_data), train_target)\n",
    "        train_pred = clf.predict_proba(get_predictors_df(train_data))[:, 1]\n",
    "        test_pred = clf.predict_proba(get_predictors_df(test_data))[:, 1]\n",
    "\n",
    "        score_test = roc_auc_score(test_target, test_pred)\n",
    "        test_data['pred'] = test_pred\n",
    "        score_coupon_test = myauc(test_data)\n",
    "\n",
    "        scores.append(round(score_test,4))\n",
    "        score_coupons.append(round(score_coupon_test,4))\n",
    "\n",
    "    print(classifier + \"总体AUC:\", scores)\n",
    "    print(classifier + \"Coupon AUC:\", score_coupons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>if_fd</th>\n",
       "      <th>full_value</th>\n",
       "      <th>reduction_value</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.812785</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1439408</td>\n",
       "      <td>11002</td>\n",
       "      <td>20160528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.939117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1439408</td>\n",
       "      <td>8591</td>\n",
       "      <td>20160613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.939117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1439408</td>\n",
       "      <td>8591</td>\n",
       "      <td>20160516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.761035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>2029232</td>\n",
       "      <td>1532</td>\n",
       "      <td>20160530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.939117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>2029232</td>\n",
       "      <td>12737</td>\n",
       "      <td>20160519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  distance  if_fd  full_value  reduction_value  label  \\\n",
       "0       0.812785       0.1    1.0    0.500000             0.20      0   \n",
       "1       0.939117       0.0    1.0    0.066667             0.01      0   \n",
       "2       0.939117       0.0    1.0    0.066667             0.01      0   \n",
       "3       0.761035       0.0    1.0    0.100000             0.05      0   \n",
       "4       0.939117       0.0    1.0    0.066667             0.01      0   \n",
       "\n",
       "   user_id  coupon_id  date_received  \n",
       "0  1439408      11002       20160528  \n",
       "1  1439408       8591       20160613  \n",
       "2  1439408       8591       20160516  \n",
       "3  2029232       1532       20160530  \n",
       "4  2029232      12737       20160519  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1特征\n",
    "train = train_f1.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征f1, 不同模型5折训练Score：\n",
      "NB总体AUC: [0.6484, 0.6538, 0.6574, 0.6504, 0.6634]\n",
      "NBCoupon AUC: [0.5364, 0.5338, 0.5335, 0.5415, 0.5385]\n",
      "LR总体AUC: [0.663, 0.661, 0.6641, 0.6626, 0.6707]\n",
      "LRCoupon AUC: [0.5364, 0.5338, 0.5335, 0.5415, 0.5385]\n",
      "RF总体AUC: [0.6842, 0.684, 0.6847, 0.682, 0.6867]\n",
      "RFCoupon AUC: [0.5297, 0.527, 0.5199, 0.5302, 0.5371]\n",
      "LGB总体AUC: [0.6853, 0.6852, 0.6855, 0.683, 0.6888]\n",
      "LGBCoupon AUC: [0.5332, 0.5264, 0.5266, 0.5324, 0.5405]\n"
     ]
    }
   ],
   "source": [
    "print('特征f1, 不同模型5折训练Score：')\n",
    "classifier_df_score(train, 'NB', 5)\n",
    "classifier_df_score(train, 'LR', 5)\n",
    "classifier_df_score(train, 'RF', 5)\n",
    "classifier_df_score(train, 'LGB', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>if_fd</th>\n",
       "      <th>full_value</th>\n",
       "      <th>reduction_value</th>\n",
       "      <th>...</th>\n",
       "      <th>user_merchant_common_buy_rate</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832624</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>163606</td>\n",
       "      <td>5054</td>\n",
       "      <td>20160421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94107</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>9871</td>\n",
       "      <td>20160409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  distance  if_fd  full_value  reduction_value  ...  \\\n",
       "0       0.863014       0.0    1.0    0.666667             0.20  ...   \n",
       "1       0.786910       1.0    1.0    0.666667             0.30  ...   \n",
       "2       0.863014       0.2    1.0    0.666667             0.20  ...   \n",
       "3       0.863014       1.0    1.0    0.666667             0.20  ...   \n",
       "4       0.761035       1.0    1.0    0.100000             0.05  ...   \n",
       "\n",
       "   user_merchant_common_buy_rate  label  user_id  coupon_id  date_received  \n",
       "0                            0.0      0  1832624       7610       20160429  \n",
       "1                            0.0      0   163606       5054       20160421  \n",
       "2                            0.0      0    94107       7610       20160412  \n",
       "3                            0.0      0  4061024       7610       20160426  \n",
       "4                            0.0      0  4061024       9871       20160409  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f2特征\n",
    "train = train_f2.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征f2, 不同模型5折训练Score：\n",
      "NB总体AUC: [0.8221, 0.8041, 0.7474, 0.7364, 0.7399]\n",
      "NBCoupon AUC: [0.6307, 0.6121, 0.6074, 0.6123, 0.6025]\n",
      "LR总体AUC: [0.8381, 0.8333, 0.7837, 0.773, 0.7758]\n",
      "LRCoupon AUC: [0.6294, 0.624, 0.6095, 0.6104, 0.6071]\n",
      "RF总体AUC: [0.7931, 0.7881, 0.7719, 0.7782, 0.7915]\n",
      "RFCoupon AUC: [0.5866, 0.5412, 0.5281, 0.5546, 0.5605]\n",
      "LGB总体AUC: [0.8747, 0.8741, 0.8476, 0.8409, 0.8435]\n",
      "LGBCoupon AUC: [0.6357, 0.5926, 0.6031, 0.6113, 0.6068]\n"
     ]
    }
   ],
   "source": [
    "print('特征f2, 不同模型5折训练Score：')\n",
    "classifier_df_score(train, 'NB', 5)\n",
    "classifier_df_score(train, 'LR', 5)\n",
    "classifier_df_score(train, 'RF', 5)\n",
    "classifier_df_score(train, 'LGB', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>if_fd</th>\n",
       "      <th>full_value</th>\n",
       "      <th>reduction_value</th>\n",
       "      <th>...</th>\n",
       "      <th>day_gap_after</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832624</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>163606</td>\n",
       "      <td>5054</td>\n",
       "      <td>20160421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94107</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>9871</td>\n",
       "      <td>20160409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  distance  if_fd  full_value  reduction_value  ...  \\\n",
       "0       0.863014       0.0    1.0    0.666667             0.20  ...   \n",
       "1       0.786910       1.0    1.0    0.666667             0.30  ...   \n",
       "2       0.863014       0.2    1.0    0.666667             0.20  ...   \n",
       "3       0.863014       1.0    1.0    0.666667             0.20  ...   \n",
       "4       0.761035       1.0    1.0    0.100000             0.05  ...   \n",
       "\n",
       "   day_gap_after  label  user_id  coupon_id  date_received  \n",
       "0            0.0      0  1832624       7610       20160429  \n",
       "1            0.0      0   163606       5054       20160421  \n",
       "2            0.0      0    94107       7610       20160412  \n",
       "3            0.0      0  4061024       7610       20160426  \n",
       "4            0.0      0  4061024       9871       20160409  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f3特征\n",
    "train = train_f3.copy()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征f3, 不同模型5折训练Score：\n",
      "NB总体AUC: [0.8536, 0.8388, 0.7909, 0.7804, 0.7833]\n",
      "NBCoupon AUC: [0.7132, 0.7057, 0.707, 0.714, 0.7066]\n",
      "LR总体AUC: [0.8662, 0.8668, 0.8266, 0.8166, 0.8165]\n",
      "LRCoupon AUC: [0.72, 0.7278, 0.7238, 0.7431, 0.7314]\n",
      "RF总体AUC: [0.8561, 0.8594, 0.8464, 0.8457, 0.8497]\n",
      "RFCoupon AUC: [0.715, 0.7009, 0.6999, 0.7258, 0.727]\n",
      "LGB总体AUC: [0.9017, 0.9034, 0.8862, 0.8812, 0.8828]\n",
      "LGBCoupon AUC: [0.7441, 0.7412, 0.7498, 0.7679, 0.7631]\n"
     ]
    }
   ],
   "source": [
    "print('特征f3, 不同模型5折训练Score：')\n",
    "classifier_df_score(train, 'NB', 5)\n",
    "classifier_df_score(train, 'LR', 5)\n",
    "classifier_df_score(train, 'RF', 5)\n",
    "classifier_df_score(train, 'LGB', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对比训练集上不同算法的运算结果可以发现，F1特征集因为特征比较少，有严重的欠拟合，所以所有算法的分数都比较低。\n",
    "F2特征集通过滑窗增加统计特征，它的分数比f1有了飞跃性的提高，其实在现实的业务场景F2+LR已经是一个很常用的解决方案了。之所以在实际作业中更倾向逻辑回归而不是类似LightGBM的算法，是为了减少计算量。当然如果计算资源不是问题的话，LightGBM也是一个好选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证结果可视化分析\n",
    "将验证结果可视化主要通过绘制**学习曲线**和**验证曲线**来实现。<br/>\n",
    "（1）学习曲线就是通过画出不同大小训练集和交叉验证的准确率，观察模型在新数据上的表现来**判断模型是否存在方差过高或偏差过高，以及增大训练集是否可以减少过拟合等**。<br/>\n",
    "（2）验证曲线和学习曲线的区别：横轴为某个**超参数**的一系列值，由此来看是不同参数设置下的准确率，而不是不同训练集大小下的准确率。从验证曲线上可以看到，随着超参数设置的改变，模型可能会有从欠拟合到合适再到过拟合的过程，进而可以选择一个合适设置来提高模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画学习曲线\n",
    "def plot_learning_curve(estimator,\n",
    "                        title,\n",
    "                        X,\n",
    "                        y,\n",
    "                        ylim=None,\n",
    "                        cv=None,\n",
    "                        n_jobs=1,\n",
    "                        train_sizes=[0.01, 0.02, 0.05, 0.1, 0.2, 0.3]):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=myeval,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes,\n",
    "                     train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes,\n",
    "                     test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.1,\n",
    "                     color=\"g\")\n",
    "    plt.plot(train_sizes,\n",
    "             train_scores_mean,\n",
    "             'o-',\n",
    "             color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes,\n",
    "             test_scores_mean,\n",
    "             'o-',\n",
    "             color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "\n",
    "#画算法的学习曲线,为加快画图速度，最多选20%数据\n",
    "def plot_curve_single(traindf,\n",
    "                      classifier,\n",
    "                      cvnum,\n",
    "                      train_sizes=[0.01, 0.02, 0.05, 0.1, 0.2, 0.3]):\n",
    "    X = get_predictors_df(traindf)\n",
    "    y = get_target_df(traindf)\n",
    "    title = \"learning curve of \" + classifier + \", cv:\" + str(cvnum)\n",
    "    estimator = get_sklearn_model(classifier)  #建模\n",
    "    plot_learning_curve(estimator,\n",
    "                        title,\n",
    "                        X,\n",
    "                        y,\n",
    "                        ylim=(0, 1.01),\n",
    "                        cv=cvnum,\n",
    "                        train_sizes=train_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1特征集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f1, \"LR\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f1, \"NB\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU9bn48c8zk5CFkLCKKCigYBsI++rC4nZxqYraq4httUq0LtV6q6L0WqvFovd3K6JelbrWpuCKpS3WKgKCG4tFERRBKrKDUQIhAbI8vz++ZyaTyUwSICeZMM/79TqvOed7vud7nplMznPW74iqYowxJnkFmjoAY4wxTcsSgTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoExxiQ5SwQmLhH5SkROb6J1F4tI96ZYd6IRkY4i8o6I7BaR/23qeMzhxxKBSUiqmqWq65o6jgSRD3wDZKvqf0XPFJFnRWS/lyh2i8inIvI7Ecnx5t/pJdZiEdkrIhUR0ysb601ExFkcMQQba/0mPksEptEdDv/8IpLSiKs7FliltT/9+YCqtgI6AFcCw4B3RaSlqt7nJdYs4Frg/dC0qvbyP/wacWZFDBWNvH4TgyUCUy8iEhCRiSLypYgUisiLItI2Yv5LIrJVRIq80xi9IuY9KyKPicgcEdkDjPbKHhWRv3t7sR+KyHERy6iIHB+xfG11zxSR1d66/09EFojI1XHeR9DbQ/7Sa2uZiHQRka7eOlMi6s4PtSMiV4jIuyLyoIh8C9wrIjtFpHdE/Q4iUioiR3jT54rIcq/eeyLSp5bP90QRWeK9hyUicmLovQM/AW7z9qBrPVWnqntVdQlwHtAOlxQOmYhMEJHPvM9slYgM8L4PL0fVe0hEpjXEOk3jsURg6uvnwAXASOAo4Dvg0Yj5rwM9gCOAj4CCqOUvAyYDrYBFXtk44DdAG2CtNz+emHVFpD3wMnAHbsO3GjixlnZu8do6G8gGfgqU1FI/0lBgHe493gO86rUV8p/AAlXdLiIDgKeBa7y4ngBmi0hadKNeQv07MM2r+3vg7yLSTlWvwH2WoT3pt+oTqKruBt4ETqnne4tLRH4I3A38GPeZnQcUAjOAs0Uk26sXxH0Gf/amJ4rI36Kau05EvvUS8EWHGptpGJYITH1dA0xS1Y2qug+3Ybg4tAetqk+r6u6IeX1D56g9f1HVd1W1UlX3emWvqupiVS3Hbez61bL+eHXPBlaq6qvevGnA1lrauRr4laquVudjVS2s52ewWVUfVtVyVS3FbfAiE8FlXhnABOAJVf1QVStU9TlgH+6UTbRzgDWq+rzX9gzgc+AH9YwrbrxA2zpr1e1qXCJa4n1ma1V1vaquxyX9C7x6pwIlqvoBgKpOUdVzI9qZRtXOwn8Dz4rISQ0QnzlElghMfR0LzPJOc+wEPgMqgI7e6ZYp3umWXcBX3jLtI5bfEKPNyA12CZBVy/rj1T0qsm3vPPrGWtrpAnxZy/zaRL+Ht4EMERkqIsfiktMsb96xwH+FPi/vM+vixRvtKGB9VNl64OiDjDPkaODbQ2wDav/MIpNhZCKsQVU/UtVCL9nNwSX0CxsgPnOILBGY+toAnKWqrSOGdFXdhNsAnA+cDuQAXb1lJGJ5v7q53QJ0Dk2IiEROx7ABOC5G+R7vNTOi7MioOtXeg6pWAi/iNoSXAX/zTsmE1jM56vPK9Pb2o23GJY5IxwCbankftRKRLNzfY+HBthEh3mcG8BIwSkQ6A2OpJRHEoFT/jpgmYonA1NfjwGRvzzd0YfR8b14r3GmPQtyG9L5GjOvvQJ6IXOCdprqemhvwSE/iLvT2EKePdy5+B27De7l3hPNT4m/8Iv0ZuAQYT/WN4B+Aa72jBRGRliJyjoi0itHGHKCniFwmIikicgmQC0SfX6+TiKSJyEDgNdx1nGfqudx8Ebk7zuwngV+KyEDvvRwf+h54n9t8bz3/VtXPalnHxSKSJe7GgzOBy4HZ9X1vxj+WCEx9PYT7p/2niOwGPsBdPAX4I+5UxiZglTevUajqN8APgQdwiSgXWIpLTLH8HrcX/09gF/AUkOHNmwDc6rXTC3ivHuv/EHc0cRTugnmofKnX3iO4DfJa4Io4bRQC5wL/5a37NuBc773V123e3+Vb3N9jGXCiqu6pfbGwLsC7ceJ7CXdx/s/AblySibz28Gfc0Ue1owHv7qzXI4puwn1HdgL/A0xQ1fn1jM/4SOyHaczhREQCuGsE41V1XlPH0xx4p3VeUtXhTR2LaRp2RGCaPRH5DxFp7d2aeSfuvHOjHZU0d96dYJYEkpglAnM4GI67q+Ub3C2XF3i3dxpj6sFODRljTJLz7YhARJ4Wke0i8mmc+SIi00RkrYh84j2JaYwxppH52XHWs7g7Jv4YZ/5ZuKcMe+DuPnmMqrtQ4mrfvr127dq1WtmePXto2bLlIYTaeCxWf1is/rBY/dEUsS5btuwbVe0Qc6aq+jbgHiz6NM68J4BxEdOrgU51tTlw4ECNNm/evBplicpi9YfF6g+L1R9NESuwVONsV5vyYvHRVH9kfyOH/ki9McaYA+TrxWIR6Yp77L53jHl/B36nqou86bnAbaq6LEbdfNyPc9CxY8eBM2fOrDa/uLiYrKzauqlJHBarPyxWf1is/miKWEePHr1MVQfFnBnvUKEhBuzUUA0Wqz8sVn9YrP5ItFNDjfkrS9FmAzeIyEzcReIiVd3ShPEY06TKysrYuHEje/furbtyI8nJyeGzz+J2H5RQLFYnPT2dzp07k5qaWu9lfEsEIjIDGAW0F5GNwK+BVABVfRzX0dbZuD5YSmigX1IyprnauHEjrVq1omvXrrhOVJve7t27adUqVj95icdidWd4CgsL2bhxI926dav3cr4lAlUdV8d8xfUUaYwB9u7dm1BJwDQ/IkK7du3YsWPHAS1nXUwYk0AsCZhDdTDfIUsExhiT5CwRGGMAKCwspF+/fvTr148jjzySo48+mpNOOol+/fqxf//+erVx5ZVXsnr16lrrPProoxQUFDREyKaBNOVdQ8aYQ1FQAJMmwddfwzHHwOTJMH78QTfXrl07li9fDsDdd99NVlYW11xzTbWLmqHbDQOB2PuQzzxT9w+iXX99Yl4arOu9Hc6S7x0bczgoKID8fFi/HlTda36+K29ga9eupXfv3lx77bUMGDCALVu2kJ+fz6BBg+jVqxf33HNPuO7JJ5/M8uXLKS8vp3Xr1kycOJG+ffsyfPhwtm/fDsCvfvUrpk6dGq4/ceJEhgwZwgknnMB777kfhduzZw8XXXQRffv2Zdy4cQwaNCicpCLdeuut5Obm0qdPH+666y4Atm7dyvnnn0+fPn3o27cvH374IQAPPPAAvXv3pnfv3jz88MNx39vrr7/O8OHDGTBgAJdccgl79tT3R96aLzsiMCYR3XwzxNjwhX3wAeyL+jXOkhK46ir4wx9iL9OvH3gb4AO1atUqnnnmGR5//HEApkyZQtu2bSkvL2f06NFcfPHF5ObmVlumqKiIkSNHMmXKFG655RaefvppJk6cWKNtVWXx4sXMnj2be+65h3/84x88/PDDHHnkkbzyyit8/PHHDBhQs3Pibdu2MWfOHFauXImIsGGD67Hm+uuv54wzzuCGG26gvLyckpISFi9eTEFBAYsXL6aiooIhQ4YwcuRIMjMzq7237du3M2XKFObOnUtmZiaTJ0/moYce4s477zyoz625sCMCY5qj6CRQV/khOu644xg8eHB4esaMGQwYMIABAwbw2WefsWrVqhrLZGRkcNZZZwEwcOBAvvrqq5htX3jhhTXqLFq0iEsvvRSAvn370qtXrxrLtW3blkAgwIQJE5g1a1a4N8/58+dzzTXXAJCSkkJ2djYLFy7koosuIjMzk1atWnHBBRewaNGiGu/tvffeY9WqVZx44on069ePgoKCuHEfTuyIwJhEVNeee9eu7nRQtGOPhfnzGzycyC6T16xZw0MPPcTixYtp3bo1l19+ecynoVu0aBEeDwaDlJeXx2w7LS2tRh2tRx9oqampLF26lDfffJOZM2fy8MMP8/bbbwM1b6Gsrb3I96aqjBkzhueff77O9R9O7IjAmOZo8mTIzKxelpnpyn22a9cuWrVqRXZ2Nlu2bOGNN95o8HWcfPLJvPjiiwCsWLEi5hHH7t272bVrF+eeey4PPvggn3zyCQCjR48On8KqqKhg165djBgxglmzZlFaWkpxcTF/+ctfOOWUU2q0eeKJJ7JgwQLWrVsHuGsVa9asafD3l2jsiMCY5ih0d1AD3jVUXwMGDCA3N5fevXvTvXt3TjrppAZfx4033siPf/xj+vTpw4ABA+jduzc5OTnV6hQVFXHhhReyb98+Kisrue+++wB45JFHmDBhAk888QQpKSk88cQTDBkyhHHjxoVPAf3sZz8jLy+PtWvXVmuzY8eOPPXUU1xyySXhW2bvu+8+evTo0eDvMaHE640uUQfrfbTxWKz+iBfrqlWrGjeQeti1a1eTrLesrExLS0tVVfWLL77Qrl27allZWa3LNFWsB8PvWGN9l0jQ3keNMSam4uJiTjvtNMrLy1HV8N698Yd9ssaYhNO6dWuWLavxG1XGJ3ax2BhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYE7Z161YuvfRSjjvuOHJzc7nooov44osvmjqsmLp27co333wDuAfBYrniiit4+eWXa23n2WefZfPmzeHpq6++OuYDbIczSwTGNFMFKwroOrUrgd8E6Dq1KwUrDq3nUVVl7NixjBo1ii+//JJVq1bx61//mm3btlWrV1FRcUjr8UOo19KDEZ0InnzyyRod6CWCeF10NARLBMY0QwUrCsj/az7ri9ajKOuL1pP/1/xDSgbz5s0jNTWVa6+9NlzWp08fTjnlFObPn8/o0aO57LLLyMvLA+D3v/99uFvnULfSe/bs4ZxzzqFv37707t2bF154AYCJEyeGu4v+5S9/WWPdjz32GLfddlt4+tlnn+XGG28E4IILLmDgwIH06tWL6dOnx4w9KysLcMnshhtuIDc3l3POOSfc9TXAPffcw+DBg+nduzf5+fmoKi+//DJLly5l/Pjx9OvXj9LSUkaNGsXSpUsB17leXl4evXv35vbbb6+2vkmTJtG3b1+GDRtWI1kCLFiwIPxDP/3792f37t2A6w572LBh9O3bN9wb6/Llyxk2bBh9+vRh7NixfPfddwCMGjWKO++8k5EjR/LQQw+xY8cOLrroIgYPHszgwYN599134/9BD0S8J80SdbAnixuPxeqP+jxZfNPrN+nIZ0bGHdLuTVPupsaQdm9a3GVuev2mWuN66KGH9Oabb65WFnoCdt68eZqZmanr1q1TVdWlS5dq7969tbi4WHfv3q25ubn60Ucf6csvv6xXX311ePmdO3dqYWGh9uzZUysrK1VV9bvvvqux7u3bt+txxx0Xnh4zZowuXLhQVVULCwtVVbWkpER79eql33zzjaqqHnvssbpjxw5VVW3ZsqXu2rVLX3nlFT399NO1vLxcN23apDk5OfrSSy9Va0dV9fLLL9fZs2erqurIkSN1yZIl4Xmh6U2bNmmXLl10+/btWlZWpqNHj9ZZs2apqioQXv7WW2/Ve++9t8Z7Ovfcc3XRokWqqrp7924tKyvTOXPm6PDhw3Xr1q3VYsrLy9P58+erqup///d/60033RSO5Wc/+1m4zXHjxoU/l/Xr1+v3vve9GutVPfAni+2IwJhmaF9F7O6m45U3hCFDhtCtWzfAdRM9duxYWrZsSVZWFhdeeCELFy4kLy+Pt956i9tvv52FCxeSk5NDdnY26enpXH311bz66qtkRneWB3To0IHu3bvzwQcfUFhYyOrVq8N9GE2bNi28571hw4ZaO4F75513GDduHMFgkKOOOopTTz01PG/evHkMHTqUvLw83n77bVauXFnr+12yZAmjRo2iQ4cOpKSkMH78eN555x3A9ax67rnnAvG72D7ppJO45ZZbmDZtGjt37iQlJYW33nqLK6+8MvwZtG3blqKiInbu3MnIkSMB+MlPfhJeD8All1wSHn/rrbe44YYb6NevH+eddx67du0KH2kcCnuy2JgENHVM7d1Qd53alfVFNbuhPjbnWOZfMf+g1tmrV69aL6xGd9ccS8+ePVm2bBlz5szhjjvu4Mwzz+Suu+5i8eLFzJ07l5kzZ/LII4/w5ptvMnDgQADOO+887rnnHi655BJefPFFvve97zF27FhEhPnz5/PWW2/x/vvvk5mZyahRo2J2eR0pugtqgL1793LdddexdOlSunTpwt13311nO/HeI7gusEPridfF9sSJEznnnHOYM2cOw4YN46233kJVY8ZXm8jPvbKykvfff5+MjIwDaqMudkRgTDM0+bTJZKZW37POTM1k8mkH3w31qaeeyr59+/hDxC+cLVu2jAULFtSoO2LECF577TVKSkrYs2cPs2bN4pRTTmHz5s1kZmZy+eWX88tf/pKPPvqI4uJiioqKOPvss5k6dSrLly8nGAyyfPlyli9fHv6pywsvvJDXXnuNGTNmhPeCi4qKaNOmDZmZmXz++ed88MEHtb6HESNGMHPmTCoqKtiyZQvz5s0DCG/027dvT3FxcbWE16pVq5h71UOHDmXBggV88803VFRUMGPGjPBee318+eWX5OXlcfvttzNo0CA+//xzzjzzTJ5++mlKSkoA+Pbbb8nJyaFNmzYsXLgQgOeffz7ues4880weeeSR8HSsn+88GHZEYEwzND7PdTc9ae4kvi76mmNyjmHyaZPD5QdDRJg1axY333wzU6ZMIT09nc6dO/PII4+wadOmanUHDBjAFVdcwZAhQwB3y2X//v154403uPXWWwkEAqSmpvLYY4+xe/duzj//fPbu3Yuq8uCDD8Zcf5s2bcjNzWXVqlXhdseMGcPjjz9Onz59OOGEExg2bFit72Hs2LG8/fbb5OXl0bNnz/AGtXXr1kyYMIG8vDy6du1a7dfWrrjiCq699loyMjJ4//33w+WdOnXid7/7HaNHj0ZVOfvsszn//PPr/XlOnTqVefPmEQwGyc3N5ayzziItLY3ly5czcuRI0tPTOfvss7nvvvt47rnnuPbaaykpKaF79+4888wzMducNm0a119/PX369KG8vJwRI0aEf3vhkMS7eJCog10sbjwWqz+sG2p/WKxV7GKxMcaYA2KJwBhjkpwlAmMSiNZyp4ox9XEw3yFLBMYkiPT0dAoLCy0ZmIOmqhQWFpKenn5Ay9ldQ8YkiM6dO7Nx40Z27NjR1KGE7d2794A3Kk3FYnVCd3sdCEsExiSI1NTU8JO7iWL+/Pn079+/qcOoF4v14NmpIWOMSXKWCIwxJsn5mghEZIyIrBaRtSIyMcb8Y0Rknoj8S0Q+EZGz/YzHGGNMTb4lAhEJAo8CZwG5wDgRif61h18BL6pqf+BS4P/8iscYY0xsfh4RDAHWquo6Vd0PzASiO+pQINsbzwE2Y4wxplH5edfQ0cCGiOmNwNCoOncD/xSRG4GWwOk+xgOqcIBdwBpjzOFO/Hp4RUR+CPyHql7tTf8IGKKqN0bUucWL4X9FZDjwFNBbVSuj2soH8gE6duw4cObMmdXWVVxcHP6pulqF+gxPabq7ZusdawKwWP1hsfrDYq3d6NGjl6nqoJgz4/VGd6gDMBx4I2L6DuCOqDorgS4R0+uAI2pr95B6H926VXXlStU1a1SLi+u3TAM7HHrJTEQWqz8sVn80Raw0Ue+jS4AeItJNRFrgLgbPjqrzNXAagIh8H0gH/H2sMj0dWrSADRtgy5aqowRjjElSviUCVS0HbgDeAD7D3R20UkTuEZHzvGr/BUwQkY+BGcAVXuZqWAUF0LUrdOoEp5wCs2dDdjbs2QNffeVejTEmSfl6slxV5wBzosruihhfBZzkZwwUFEB+Png/DcfmzXDbbW78wgvdEcGGDZCTAx06NOn1A2OMaQqH/5PFkyZVJYGQ0lKYMsWNp6S4o4OSEnd0UFzc6CEaY0xTOvwTwddfxy7ftAneecclBYCMDHft4LHHoHNnCATc6aSCgkYL1RhjmsLhfx7kmGNg/frY88aNg9RUGDAATjrJnSb6wx+qksP69TBhgiv/8Y/tGQRjzGHp8E8EkydXv0YAbu//3nvhyCPh3Xfhvfdg6lSorKy5fGkp3HmnSxTZ2dCypbvzKBhsvPdgjDE+OvwTwfjx7nXSJHeaqFMnuOMOd6EYYPRo91pUBLnRXSF5Nm92p4gGD4bu3d2RQUaGu8Acuh3VjhaMMc3U4Z8IwCWD8eNh2zZ3q2isXwbKyYGjj3bXDqIFg3D33W68fXt3dDBsmEsMXbq46wmtWkFWlh0tGGOaneRIBPWhCrfeChMnwt69VeUZGfDAAzBkiDuNtGiRe/3LX9z8Ll3gxBNh6FBXp317t0x2dtUFaDtaMMYksORLBJWVbkNfUVH9mkAw6E4XpaXBfffBxo3uCOGWW+CMM1ydH/wALrrI1V27tiox/OMf8MILrk7Pni4xDB7shjZtqo4W0tIa//0aY0wdkisRpKa65wbS0qrO7aekuCF0Oufaa90Qqbwc9u93F46Li93ppU6d4Ic/hMsuc6eGVq2qOlp44QV49llXnpfnjhaGDYP+/V07330HmZl2tGCMSQjJlQjatnXDgQoli8xMaNfOHU3s3++OLIqLXYLo1g2OOw6uusqdZvr4Y5cYFi2Cp5+G6dOhRQv6fe977gL10KHQr1/VEUNamksgoYvaxxzj7ngKXew2xhifJFciaCjBoDv/n5HhNuSqLjHs2+cSQ0kJ9Orlhuuug7IyWLYM3n2X4JtvwrRpbpmWLd3poyFDXJ3HH6/+DEN+vhu3ZGCM8ZElgoYg4vbo09LcRWJVt2Hfv9+dRtqzBwYNgsGDWXb++Yw68khYsqTqVNL8+bHbLSmBn//cJZ5WrdyQne3ucMrOrjq1FAhUH0JldtrJGFMPlgj8IOI20i1auIvEUHWd4euv3YZ8xAjXE2ogAIWFMHx47La+/dY9AR1LRoY7qsjMrD60bFl9CCWRrCyXQLKzq8oiE0x2tjsF1pAJpKDATncZk+AsETSW0HWGlBTXh1HkdYb0dDjqKPfgWrQOHdyppD173BFCSUnVeOjCdagsNGzfXjVeUuLWU18ZGeFkMigYdNdEQkkkNEQmldB4KJlEzp8zB266qeqpbjvdlZgsWSc9SwRNJfo6w/33wzXX1OwK48473TUEcLe7qrrhQOzfX5VEIhNJ9HhUnb07dpAF7ohlw4bq9cvKDu59l5S4fptuvdUdDQWDVUNoOro8en6M8l47d8IRR8RfJnRnWG1tpaQc+LoPIt6s1auhdetDbodAA/QZGd1NuyXrxORzsrZEkCguv9ydkqnvHzuUDCITw6GMRyYZb/zT5csZlZdXNT/03EXoWYzSUti9u+roo7i46mL5nj3w61/Hjr2y0j1rUVlZ9TxH6DVyiJxXUeGST3T9igpQJXPvXvdUeFR5zPqx2m9EsX809iDVliRizYsuW726ZlIvKXF3v02fTt9du9yddpHXnuJdk4pVHlpnqE4wWPt1rUMo7/zll/DJJ7603SBtRJSnb9nikm592nj5ZbjxRl9vJLFEkEhCXWHUR+g8vp8XhFNSoGPHg1tWFZ56KnY34MccAzNnVj+yiT7KOcDpJe+/z6hhww6+vfLyqsRQXl41XVFRNR2aFyqLrB9ZFqobuXxE4lmxcSN5RxxRvU5k4oqXvKIT44Ekunhln35a8+8D7g64vXuR8nLXD1f0jkBoiNhxqPYavWNRn3l11a3D8XXWSBzD6q5Su5ISt9NoicAkNBH3hHZ0z6+Zma68oX8JLhBwbTcDhfPnw6hR/jR+oAmwe/f4yXrRIpYvWsSok0+OvWxt7R5IeV3joUQQmfhiHDku+te/ODkvryqJRNaNVRadTOON1zZEJrBQe7GSZOQ84LNNm/h+x461J9HQ6733UpAHk06Dr3PgmCKYPBfGfxrnt1YOgiUC45/onl/tQqT/oo8Q6zpivO8+Ch68kkmnlFVtZBamMv4X97kn8UXcazNQ/u9/u4c6m4Ft8+fz/XruDBQs/D/yTyykpIWbXt8a8n8AtGtLQ/0nWSIw/jqQ012m0RX0gfzzhBJv53t9azdNHxpsI5NIVBVFqdRKKrUS1arxSq2sNq8+8w+2jRVFKwisD4TnV1RWxFy+Qiu4+dT9lET9VEpJC5h0esP9jSwRGF8VrChg0txJfF30NcfkHMPk0yYzPu9w3MTUTlWp0ArKK8sprSjlu9LvKK8sjzmUVZRRXlkerl9WWUZFZUXc+qGhQisoq4ioq1XLVlRWUFbptRsx/9nlz1Ki1W8vLtH95P81n7+t/hs7tu/g0e2P1ty4oVRWetPUvjGsMc+bjtlmrHp11A/NLysvI/B+oNry0csklOWHtvjX5d82TBxYIjCHIPSPFm98xooZXPf36ygpd9cI1hetZ8LsCezYs4Nze55btRGrcBul0AYqvOHzysIbRq+svKI8vCErr3D1v9r0FUveXVJzYxexkaw2HTE/cl5FZUXMuqGyyLhCy0aOl1eWU6mV1dZRoRU1N0KLGvVPFRaQAAEJkBJIIShB9pTtiVmvpKyERRsWUbm/kpT9KW45AogIIhIeD0igWrsigiDh8YAEENwywUCQVFJjthFrmVhthNcTPS3Cnm/2kN0hu+b8yLhjrCNW/UCg5joAghKs0W6s9x6z3UDVOret28ZRxx8F6tqMXj4YqCrL/2s+O0p21PgbHZNzTIN9LywRJJC69p7Vu3imaI3x6I1wrPmqSmlZKSVlJZSWl1aNl5W66XI3vbd8L6XlpXy18Svmvj2X0vJS9pbvrTHsq9jnXsv3hafD4+X7KNpXFI4rpLS8lF+88Qt+8cYvGv4DXBt/VmoglWAgSFCCBANBUiTFvQZSwv90oY1jqCxUN1SWlpIWXi48L6Kt6PqBQKDGvBRJoWhrER06dyBFvDreesNtBb36EjHtzQvHGaorQQLBQHg8JZBCatC911TxXoOpBMW9Rm7UAhJg6JND2bS75o8xdc7uzEf5H/Hxhx/Td2jfcHlo2cdmjTkAABc8SURBVEixyg6krsS5jiHULI9VN1Tvg0UfMOzkYQ3SZqy6DdnmgqIFjOwzsta6IXvK9pD/13xKyqpuushMzWTyaZNrXe5AWCJoYqFTBs9//DzXz7me0nJ3r/D6ovX89LWf8voXr9PriF6UlrmN8b7Kfewr28feCrcx3l+xv2rDXL6v+sa5onrZ/ooDeMI45Ev3IgjpKelxh/aZ7UkLppGekk5aint97uPn4jY7+dTJbqMW2lBGbCwDEqjamEr1DWXkhjo8X1LY9Pkmuud1J0jVBjpy4xn+Xw3lpajpgPdwVgD3GvrnjNxo1vUa2vsL7dlFT4faXfzuYoaeNDQ8HTkv9FkfyvSBuP+M+2NuZKacPoUOLTuQEkihQ8sOB9xuUxARMlIzmjqMeqvv3yu0M+jnKVZLBI1EVSmvLEdVKSot4t9F/+aTbZ+wascq1hSu4a9f/JWyyuoP9uyv3E/BpwU12koJpFTbCIc2wKEhJz2najpYfYPdItii2sa6RbAFacE00lLc0CLQwo0H09j2+TZ69OlBWmoaqZKKBMRtOIVaXwMBd9j85ro32by7ZrcZnVt15qr+V9V7I1ufDeD769+n/5H9a8z3Y+N5qAISoGWLlo2+3lgaYyNjDt34vPG+/k0sETSw0Aa/rLKM/eX72bBrAx9v/ZjPCj9jTeEaPt3wKRs/2Mju/bvDy3TI7FAjCYQIwjtXvuM21t4GOxgIhi+GhevJgW2kI89txhv+9dW/OKHDCVV7tvV8DXngjAdi722eMYWOWQf5oFocgpCWYr8AdzD83siYxGeJ4CCFLgiG7vLYULSBFdtX8Pk3n7Pm2zWsKVzD2m/XsnPfzvAybdLb0LlFZ8Z+fywntDuBnu160r1Nd3LSchjxzAg2F9fcez6q1VEc1+a4uBvr6Itz9d1I10dAAmS1yDroz8j2No1pHiwRRIm+YPvbU3/LD3N/SHllOfsr9rO1eCsrtq/gsx2fsfbbtaz51m3wC0sLw21kp2XTs11Pzul5jtvgt+/J8W2OJycthy+Xf0m3vt1QlGAgSFowjczUTO499V5unHNj+A4bcHvP959xP51adWqKj6JB2N6mMYnPEkGEghUF1U5lrC9az0//8lOmL51OBRWs/XYt2/dsD9dvmdqSnu16ckb3M+jZvicntDuBHm170Dajbfi+5dBeeFowjYzUDFIDqXTJ6UJqMJWUQNXH/9P+PyUtJc32no0xjc4SQYQ7595Z7Xw2QFllGQs3LKRPxz6MOHYEJ7Q7wW3w2/WgY8uOVfeIe6frU4IpZKRkkJmaSWowldSA2+BH3oUS784G23s2xjQFSwSe3ft283VR7E6cBOHV/3yVisoKFA1faG0RbEFGagZpwbTw/dvx7qk2xphElfSJQFV5b8N75P81P26do1odRXZaNukp6eG9/GAg2IhRGmOMf5J697VkfwmT3p7E6OdGs23PNq4ecDXpKenV6oQu2HZo2YFWaa1IT0m3JGCMOawk5RGBqrJ863Im/HUCy7Ys46zjz2LyqZPJSMmg/5H9uf/d+9lQtMEu2BpjkoKviUBExgAPAUHgSVWdEqPOfwJ34y63fqyqlzV0HJG3hHbJ7sLQzkP5+xd/JxgIMnXMVM45/hwU5cisI7lu8HVcN/i6hg7BGGMSlm+JQESCwKPAGcBGYImIzFbVVRF1egB3ACep6ncickRDxxF9S+jXu77m61Vf07NtT/449o/kpOWQkZrBES2PIDXYPH6AwxhjGpKfRwRDgLWqug5ARGYC5wOrIupMAB5V1e8AVHV7jVYO0aS5k2rcEgpQXFZMm4w2dGzZkey07Cbpc8YYYxKBnxeLjwY2RExv9Moi9QR6isi7IvKBdyqpQcW7JXTL7i10bd2VnPQcSwLGmKTm5xFBrK1r9C9ZpwA9gFFAZ2ChiPRW1Z2RlUQkH8gH6NixI/Pnz6/WSHFxcY2ykCPSjmDbvm0xy99b+F493kbDqi3WRGOx+sNi9YfFeghU1ZcBGA68ETF9B3BHVJ3HgSsipucCg2trd+DAgRpt3rx5NcpC/vTJnzRzcqZyN+Ehc3Km/umTP8Vdxk+1xZpoLFZ/WKz+sFhrByzVONtVP08NLQF6iEg3EWkBXArMjqrzGjAaQETa404VrWvIIMbnjWf6D6ZzbM6xCMKxOccy/QfT7ZZQY4zx+HZqSFXLReQG4A3c7aNPq+pKEbkHl5lme/POFJFVQAVwq6oWxm/14FgfPsYYE5+vzxGo6hxgTlTZXRHjCtziDcYYY5pAUncxYYwxxhKBMcYkPUsExhiT5CwRGGNMkqt3IhCRk0XkSm+8g4h08y8sY4wxjaVeiUBEfg3cjnsoDCAV+JNfQRljjGk89T0iGAucB+wBUNXNQCu/gjLGGNN46psI9nv3/CuAiLT0LyRjjDGNqb6J4EUReQJoLSITgLeAP/gXljHGmMZSryeLVfX/icgZwC7gBOAuVX3T18iMMcY0ijoTgfdLY2+o6umAbfyNMeYwU+epIVWtAEpEJKcR4jHGGNPI6tvp3F5ghYi8iXfnEICq/tyXqIwxxjSa+iaCv3uDMcaYw0x9LxY/5/24TE+vaLWqlvkXljHGmMZSr0QgIqOA54CvcL9F3EVEfqKq7/gXmjHGmMZQ31ND/wucqaqrAUSkJzADGOhXYMYYYxpHfR8oSw0lAQBV/QLX35Axxphmrr5HBEtF5CngeW96PLDMn5CMMcY0pvomgp8B1wM/x10jeAf4P7+CMsYY03jqmwhSgIdU9fcQfto4zbeojDHGNJr6XiOYC2RETGfgOp4zxhjTzNU3EaSranFowhvP9CckY4wxjam+iWCPiAwITYjIIKDUn5CMMcY0pvpeI7gZeElENuN+nOYo4BLfojLGGNNoaj0iEJHBInKkqi4Bvge8AJQD/wD+3QjxGWOM8Vldp4aeAPZ748OBO4FHge+A6T7GZYwxppHUdWooqKrfeuOXANNV9RXgFRFZ7m9oxhhjGkNdRwRBEQkli9OAtyPm1ff6gjHGmARW18Z8BrBARL7B3SW0EEBEjgeKfI7NGGNMI6g1EajqZBGZC3QC/qmq6s0KADf6HZwxxhj/1Xl6R1U/iFH2hT/hGGOMaWz1faDMGGPMYcoSgTHGJDlLBMYYk+R8TQQiMkZEVovIWhGZWEu9i0VEvT6MjDHGNCLfEoH3mwWPAmcBucA4EcmNUa8V7gdvPvQrFmOMMfH5eUQwBFirqutUdT8wEzg/Rr17gQeAvT7GYowxJg6pejSggRsWuRgYo6pXe9M/Aoaq6g0RdfoDv1LVi0RkPvBLVV0ao618IB+gY8eOA2fOnFltfnFxMVlZWb68j4ZmsfrDYvWHxeqPpoh19OjRy1Q19ul3VfVlAH4IPBkx/SPg4YjpADAf6OpNzwcG1dXuwIEDNdq8efNqlCUqi9UfFqs/LFZ/NEWswFKNs13189TQRqBLxHRnYHPEdCugNzBfRL4ChgGz7YKxMcY0Lj8TwRKgh4h0E5EWwKXA7NBMVS1S1faq2lVVuwIfAOdpjFNDxhhj/ONbIlDVcuAG4A3gM+BFVV0pIveIyHl+rdcYY8yB8bUraVWdA8yJKrsrTt1RfsZijDEmNnuy2BhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcr4mAhEZIyKrRWStiEyMMf8WEVklIp+IyFwROdbPeIwxxtTkWyIQkSDwKHAWkAuME5HcqGr/Agapah/gZeABv+IxxhgTm59HBEOAtaq6TlX3AzOB8yMrqOo8VS3xJj8AOvsYjzHGmBhEVf1pWORiYIyqXu1N/wgYqqo3xKn/CLBVVX8bY14+kA/QsWPHgTNnzqw2v7i4mKysrAZ+B/6wWP1hsfrDYvVHU8Q6evToZao6KOZMVfVlAH4IPBkx/SPg4Th1L8cdEaTV1e7AgQM12rx582qUJSqL1R8Wqz8sVn80RazAUo2zXU3xMQFtBLpETHcGNkdXEpHTgUnASFXd52M8xhhjYvDzGsESoIeIdBORFsClwOzICiLSH3gCOE9Vt/sYizHGmDh8SwSqWg7cALwBfAa8qKorReQeETnPq/Y/QBbwkogsF5HZcZozxhjjEz9PDaGqc4A5UWV3RYyf7uf6jTHG1M2eLDbGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYY5KcJQJjjElylgiMMSbJWSIwxpgkZ4nAGGOSnCUCY4xJcpYIjDEmyVkiMMaYJGeJwBhjkpyviUBExojIahFZKyITY8xPE5EXvPkfikhXP+MxxhhTk2+JQESCwKPAWUAuME5EcqOqXQV8p6rHAw8C9/sVjzHGmNj8PCIYAqxV1XWquh+YCZwfVed84Dlv/GXgNBERH2MyxhgTJcXHto8GNkRMbwSGxqujquUiUgS0A76JrCQi+UC+N1ksIquj2mkfvUwCs1j9YbH6w2L1R1PEemy8GX4mglh79noQdVDV6cD0uCsSWaqqgw4svKZhsfrDYvWHxeqPRIvVz1NDG4EuEdOdgc3x6ohICpADfOtjTMYYY6L4mQiWAD1EpJuItAAuBWZH1ZkN/MQbvxh4W1VrHBEYY4zxj2+nhrxz/jcAbwBB4GlVXSki9wBLVXU28BTwvIisxR0JXHqQq4t72igBWaz+sFj9YbH6I6FiFdsBN8aY5GZPFhtjTJKzRGCMMUmuWSeCurqw8HG9T4vIdhH5NKKsrYi8KSJrvNc2XrmIyDQvxk9EZEDEMj/x6q8RkZ9ElA8UkRXeMtMO5SE7EekiIvNE5DMRWSkiNyVqvCKSLiKLReRjL9bfeOXdvC5I1nhdkrTwyuN2USIid3jlq0XkPyLKG/Q7IyJBEfmXiPwtkWMVka+8v9FyEVnqlSXcd8Brq7WIvCwin3vf2+EJHOsJ3mcaGnaJyM2JGm9cqtosB9wF6C+B7kAL4GMgt5HWPQIYAHwaUfYAMNEbnwjc742fDbyOe2ZiGPChV94WWOe9tvHG23jzFgPDvWVeB846hFg7AQO88VbAF7guPxIuXm/5LG88FfjQi+FF4FKv/HHgZ974dcDj3vilwAveeK73fUgDunnfk6Af3xngFuDPwN+86YSMFfgKaB9VlnDfAa+t54CrvfEWQOtEjTUq7iCwFffgVsLHWy32hm6wsQbvg3kjYvoO4I5GXH9XqieC1UAnb7wTsNobfwIYF10PGAc8EVH+hFfWCfg8orxavQaI+y/AGYkeL5AJfIR7Gv0bICX67467I224N57i1ZPo70KoXkN/Z3DPxswFTgX+5q07UWP9ipqJIOG+A0A28G+8G1kSOdYYsZ8JvNtc4o0cmvOpoVhdWBzdRLEAdFTVLQDe6xFeebw4ayvfGKP8kHmnI/rj9rQTMl7vVMtyYDvwJm6veKeqlsdov1oXJUCoi5IDfQ8HaypwG1DpTbdL4FgV+KeILBPXZQsk5negO7ADeMY75fakiLRM0FijXQrM8MabQ7xhzTkR1Kt7igQQL84DLT+0IESygFeAm1V1V21VDzCuBo1XVStUtR9ub3sI8P1a2m+yWEXkXGC7qi6LLK6l/ab+HpykqgNwvQFfLyIjaqnblLGm4E67Pqaq/YE9uFMr8TT15+qCcNeCzgNeqqvqAcbVKNu55pwI6tOFRWPaJiKdALzX7V55vDhrK+8co/ygiUgqLgkUqOqriR4vgKruBObjzqO2FtcFSXT78booOdD3cDBOAs4Tka9wPeueijtCSMRYUdXN3ut2YBYuySbid2AjsFFVP/SmX8YlhkSMNdJZwEequs2bTvR4q2voc02NNeD2HNbhLrCFLqb1asT1d6X6NYL/ofrFoQe88XOofnFosVfeFncutI03/Bto681b4tUNXRw6+xDiFOCPwNSo8oSLF+gAtPbGM4CFwLm4vazIC7DXeePXU/0C7IveeC+qX4Bdh7uQ58t3BhhF1cXihIsVaAm0ihh/DxiTiN8Br62FwAne+N1enAkZa0TMM4ErE/n/q9b4G7rBxhxwV+C/wJ1HntSI650BbAHKcBn7Ktz53rnAGu819EcU3A/0fAmsAAZFtPNTYK03RH6JBgGfess8QtSFswOM9WTcoeQnwHJvODsR4wX6AP/yYv0UuMsr7467c2ItbkOb5pWne9NrvfndI9qa5MWzmoi7LPz4zlA9ESRcrF5MH3vDylBbifgd8NrqByz1vgev4TaMCRmr114mUAjkRJQlbLyxButiwhhjklxzvkZgjDGmAVgiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjAJR0TaRfTmuFVENkVMt6hnG8+IyAl11LleRMY3TNSJQUQWiUi/po7DNC92+6hJaCJyN1Csqv8vqlxw39/KmAsmKRFZBNygqsubOhbTfNgRgWk2ROR4EflURB7H9UzaSUSmi8hScb9fcFdE3UUi0k9EUkRkp4hMEfc7B++LyBFend+KyM0R9aeI+z2E1SJyolfeUkRe8Zad4a2rxh63iAwWkQVep26vi0hHEUn1pk/26vyPVP3Gwm9EZEno/YT6mPfi+L2ILBSRVSIySERmeX3U3x3xOawUkee9fupfFJGMGDGd5b3fj8T9FkLLiDhWef3h39+gfyTTLFkiMM1NLvCUqvZX1U24x/gHAX2BM0QkN8YyOcACVe0LvI97gjMWUdUhwK1AKKncCGz1lp2C6721+kIiacBDwEWqOhD4E3CvqpYBVwLTReRMXH9Ev/UWe0hVBwN5XnxjIposVdVTgKdwT9Ze69XLF5HWEZ/Do6qaB+wFromK6Qhc1wanqets7hPgJhHpiHtiuZeq9gF+F+ezMEnEEoFpbr5U1SUR0+NE5CPcEcL3cRvIaKWq+ro3vgzXT1Qsr8aoczKuHxlUNdRFQ7Tv4/oMesvrQnsiXgdiqvqJt/xfcN0GlHnLnCYii3HdPoz0lg+Z7b2uAFao6jZV3Yv7TYFQB2T/VtUPvPE/eXFGOhH3WbznxTTee0/f4rrN/oOIjMX17mmSXErdVYxJKOENl4j0AG4ChqjqThH5E65Pn2j7I8YriP+93xejTn1+FlCAT7y9+Fh6435/IHRKKhPXZ8wAVd0kIr+NijsUR2XEeGg6FFf0xb3oaQH+oao/qhGsyCDcjxNdCvwM94MqJonZEYFpzrKB3cAur6vf/6ij/sFYBPwngIjkEfuIYxVwtIgM8eq1EJFe3vglQBauY7pHRSQb17NqJfCNiLQCLjqIuLqJyGBvfJwXZ6T3gJEi0t2Lo6WI9PDWl62qfwN+QYxTXSb52BGBac4+wm2EP8V12fyuD+t4GPijiHzire9T3N59mKruE5GLgWnehjYF+F8R2YG7JjDK2/N/AnhQVa8Skee8ttbjfjHuQK0EJojIU8DnwPSomLaJyFXACxG33N4JlAKvetc1ArjfXDZJzm4fNaYW4n5EJkVV93qnov4J9NCqn6NsipiOB15W90tuxhwyOyIwpnZZwFwvIQhwTVMmAWP8YEcExhiT5OxisTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoExxiS5/w9ggPk19b0i+wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f1, \"DT\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f1, \"RF\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f1, \"LGB\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F2特征集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_curve_single(train_f2, \"LR\", 5, [0.01, 0.02, 0.05, 0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在03_model_training中已经展示过学习曲线绘制<br/>\n",
    "可以发现在特征集f1上，评测分普遍比较低，是欠拟合。<br/>\n",
    "在特征集f3上决策树和随机森林都表现出过拟合。LGB表现比较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型超参空间及调参\n",
    "\n",
    "超参数是在开始学习之前设置值的参数，而不是通过训练得到的参数。在通常青果下，在机器学习过程中需要对超参数进行优化，给学习器选择一组最优超参数，以提高学习的性能和效果。比如，树的数量或深度、学习率（多种模式）及K均值聚类中的簇数等都是超参数。\n",
    "\n",
    "与超参数区别的概念是参数，它是模型训练过程中学习到的一部分，比如回归系数、神经网络权重等。\n",
    "\n",
    "简而言之，超参数是人工配置的（本质上是参数的参数，每次改变超参数模型都要重新训练），参数是训练获得的。\n",
    "\n",
    "常见的超参数搜索算法有**网格搜索**、**随机搜索**、**启发式搜索**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>if_fd</th>\n",
       "      <th>full_value</th>\n",
       "      <th>reduction_value</th>\n",
       "      <th>...</th>\n",
       "      <th>this_month_user_receive_same_coupon_firstone</th>\n",
       "      <th>this_day_receive_all_coupon_count</th>\n",
       "      <th>this_day_user_receive_same_coupon_count</th>\n",
       "      <th>day_gap_before</th>\n",
       "      <th>day_gap_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  distance  if_fd  full_value  reduction_value  ...  \\\n",
       "0       0.863014       0.0    1.0    0.666667             0.20  ...   \n",
       "1       0.786910       1.0    1.0    0.666667             0.30  ...   \n",
       "2       0.863014       0.2    1.0    0.666667             0.20  ...   \n",
       "3       0.863014       1.0    1.0    0.666667             0.20  ...   \n",
       "4       0.761035       1.0    1.0    0.100000             0.05  ...   \n",
       "\n",
       "   this_month_user_receive_same_coupon_firstone  \\\n",
       "0                                           0.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   this_day_receive_all_coupon_count  this_day_user_receive_same_coupon_count  \\\n",
       "0                                0.0                                      0.0   \n",
       "1                                0.0                                      0.0   \n",
       "2                                0.0                                      0.0   \n",
       "3                                0.0                                      0.0   \n",
       "4                                0.0                                      0.0   \n",
       "\n",
       "   day_gap_before  day_gap_after  \n",
       "0             0.0            0.0  \n",
       "1             0.0            0.0  \n",
       "2             0.0            0.0  \n",
       "3             0.0            0.0  \n",
       "4             0.0            0.0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f3\n",
    "train = get_predictors_df(train_f3)\n",
    "target = get_target_df(train_f3)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索\n",
    "\n",
    "网格搜索是在所有候选的参数选项中进行循环遍历，尝试每一种可能性，表现最好的参数就是最终的结果（暴力搜索）。\n",
    "\n",
    "原理：在一定区间内，通过循环遍历尝试每一种可能性，并计算其约束函数和目标函数的值。对满足约束条件的点，逐个比较其目标函数的值，抛弃坏的点，保留好的点，最后得到最优解的近似解。为了避免初始数据的划分对结果的影响，一般情况下网格搜索需要和交叉验证结合使用。\n",
    "\n",
    "sklearn()函数定义：<br/>\n",
    "*class sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=None, iid='warn', refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs', error_score='raise=deprecating', return_train_score='warn')*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林模型为例采用网格调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=20, total=   1.1s\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... max_depth=1, n_estimators=20, total=   1.1s\n",
      "[CV] max_depth=1, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   2.1s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   2.0s\n",
      "[CV] max_depth=1, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=1, n_estimators=50, total=   1.8s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   3.7s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   3.9s\n",
      "[CV] max_depth=1, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=1, n_estimators=100, total=   3.9s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=2, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=20, total=   1.0s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   2.4s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   2.3s\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=2, n_estimators=50, total=   2.3s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   5.0s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   4.8s\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=2, n_estimators=100, total=   4.5s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.5s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.6s\n",
      "[CV] max_depth=3, n_estimators=20 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=20, total=   1.7s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   3.6s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   3.0s\n",
      "[CV] max_depth=3, n_estimators=50 ....................................\n",
      "[CV] ..................... max_depth=3, n_estimators=50, total=   2.9s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   6.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   6.0s\n",
      "[CV] max_depth=3, n_estimators=100 ...................................\n",
      "[CV] .................... max_depth=3, n_estimators=100, total=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier GridSearchCV test AUC:    0.5298280412375206\n",
      "最优参数:\n",
      "{'max_depth': 3, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # 切分数据\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(train, target):\n",
    "    train_data = train.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    test_data = train.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [20, 50, 100], 'max_depth': [1, 2, 3]}\n",
    "\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=2)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestClassifier GridSearchCV test AUC:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行起来我们可以发现网格搜索很耗时间，每次训练及预测的次数是按照参数的个数指数增长的。所以一次不要搜索太多的参数，一般1，2个就可以了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机搜索\n",
    "\n",
    "随机搜索是利用随机数去求函数近似最优解的方法，区别于网格搜索的暴力搜索。\n",
    "\n",
    "原理：在一定区间内，不断地、随机地而不是有倾向性地产生随机点，并计算其约束函数和目标函数的值。对满足约束条件的点，逐个比较其目标函数的值，抛弃坏的点，保留好的点，最后得到最优解的近似解。随机搜索建立在概率论的基础上，所取随机点越多，得到最优解的概率也就越大。这种方法存在**精度较差**的问题，但是找到近似最优解的效率高于网格搜索。随机搜索一般用于粗选或普查。\n",
    "\n",
    "sklearn()函数定义：<br/>\n",
    "*class sklearn.model_selection.RandomizedSearchCV(estimator, param_distribution, n_iter=10, scoring=None, fit_params=None, n_jobs=None, iid='warn', refit=True, cv='warn', verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score='raise=deprecating', return_train_score='warn')*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=10, max_depth=3, total=   0.7s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... n_estimators=10, max_depth=3, total=   0.7s\n",
      "[CV] n_estimators=10, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=10, max_depth=3, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=2, total=   2.3s\n",
      "[CV] n_estimators=50, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=2, total=   2.3s\n",
      "[CV] n_estimators=50, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=2, total=   2.3s\n",
      "[CV] n_estimators=30, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=2, total=   1.5s\n",
      "[CV] n_estimators=30, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=2, total=   1.4s\n",
      "[CV] n_estimators=30, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=2, total=   1.4s\n",
      "[CV] n_estimators=30, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=3, total=   1.8s\n",
      "[CV] n_estimators=30, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=3, total=   1.8s\n",
      "[CV] n_estimators=30, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=3, total=   1.8s\n",
      "[CV] n_estimators=50, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=1, total=   1.7s\n",
      "[CV] n_estimators=50, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=1, total=   1.7s\n",
      "[CV] n_estimators=50, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=1, total=   1.7s\n",
      "[CV] n_estimators=20, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=2, total=   1.0s\n",
      "[CV] n_estimators=20, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=2, total=   1.0s\n",
      "[CV] n_estimators=20, max_depth=2 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=2, total=   1.0s\n",
      "[CV] n_estimators=30, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=1, total=   1.1s\n",
      "[CV] n_estimators=30, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=1, total=   1.0s\n",
      "[CV] n_estimators=30, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=30, max_depth=1, total=   1.1s\n",
      "[CV] n_estimators=10, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=10, max_depth=1, total=   0.4s\n",
      "[CV] n_estimators=10, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=10, max_depth=1, total=   0.4s\n",
      "[CV] n_estimators=10, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=10, max_depth=1, total=   0.4s\n",
      "[CV] n_estimators=20, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=1, total=   0.7s\n",
      "[CV] n_estimators=20, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=1, total=   0.7s\n",
      "[CV] n_estimators=20, max_depth=1 ....................................\n",
      "[CV] ..................... n_estimators=20, max_depth=1, total=   0.7s\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=3, total=   2.9s\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=3, total=   2.9s\n",
      "[CV] n_estimators=50, max_depth=3 ....................................\n",
      "[CV] ..................... n_estimators=50, max_depth=3, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   42.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier RandomizedSearchCV test AUC:    0.5304754746613455\n",
      "最优参数:\n",
      "{'n_estimators': 10, 'max_depth': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # 切分数据\n",
    "\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(train, target):\n",
    "    train_data = train.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    test_data = train.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "parameters = {'n_estimators': [10, 20, 30, 50], 'max_depth': [1, 2, 3]}\n",
    "\n",
    "clf = RandomizedSearchCV(model, parameters, cv=3, verbose=2)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict(test_data))\n",
    "\n",
    "print(\"RandomForestClassifier RandomizedSearchCV test AUC:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 启发式搜索\n",
    "\n",
    "随机搜索又称信息搜索，是利用问题拥有的启发信息来引导搜索，以达到减少搜索范围、降低问题复杂度的目的。\n",
    "\n",
    "原理：在状态空间中，对每一个搜索的位置进行评估得到最好的位置，再从这个位置进行搜索，直到目标。这样可以省略大量无谓的搜索路径，提高了搜索效率。在启发式搜索中，对未知的估价是十分重要的。\n",
    "\n",
    "启发式搜索多样化，在sklearn包中没有现成的函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F3特征集和LightGBM 网格调参\n",
    "\n",
    "LGBMClassifier参数如下：<br/>\n",
    "1.boosting_type=‘gbdt’# 提升树的类型 gbdt,dart,goss,rf<br/>\n",
    "2.num_leavel=32#树的最大叶子数，对比xgboost一般为2^(max_depth)<br/>\n",
    "3.max_depth=-1#最大树的深度<br/>\n",
    "4.learning_rate#学习率<br/>\n",
    "5.n_estimators=10: 拟合的树的棵树，相当于训练轮数<br/>\n",
    "6.subsample=1.0: 训练样本采样率行<br/>\n",
    "7.colsample_bytree=1.0: 训练特征采样率 列<br/>\n",
    "8.subsample_freq=1: 子样本频率<br/>\n",
    "9.reg_alpha=0.0: L1正则化系数<br/>\n",
    "10.reg_lambda=0.0: L2正则化系数<br/>\n",
    "11.random_state=None: 随机种子数<br/>\n",
    "12.n_jobs=-1: 并行运行多线程核心数<br/>\n",
    "13.silent=True: 训练过程是否打印日志信息<br/>\n",
    "14.min_split_gain=0.0: 最小分割增益<br/>\n",
    "15.min_child_weight=0.001: 分支结点的最小权重<br/>\n",
    "\n",
    "LightGBM 调参次序：  \n",
    "第一步：确定学习率和迭代次数  \n",
    "第二步：确定max_depth和num_leaves  \n",
    "第三步：确定min_data_in_leaf和max_bin in  \n",
    "第四步：确定feature_fraction、bagging_fraction、bagging_freq  \n",
    "第五步：确定lambda_l1和lambda_l2  \n",
    "第六步：确定 min_split_gain   \n",
    "第七步：降低学习率，增加迭代次数，验证模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>if_fd</th>\n",
       "      <th>full_value</th>\n",
       "      <th>reduction_value</th>\n",
       "      <th>...</th>\n",
       "      <th>day_gap_after</th>\n",
       "      <th>label</th>\n",
       "      <th>user_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1832624</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>163606</td>\n",
       "      <td>5054</td>\n",
       "      <td>20160421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>94107</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>7610</td>\n",
       "      <td>20160426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.761035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4061024</td>\n",
       "      <td>9871</td>\n",
       "      <td>20160409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   discount_rate  distance  if_fd  full_value  reduction_value  ...  \\\n",
       "0       0.863014       0.0    1.0    0.666667             0.20  ...   \n",
       "1       0.786910       1.0    1.0    0.666667             0.30  ...   \n",
       "2       0.863014       0.2    1.0    0.666667             0.20  ...   \n",
       "3       0.863014       1.0    1.0    0.666667             0.20  ...   \n",
       "4       0.761035       1.0    1.0    0.100000             0.05  ...   \n",
       "\n",
       "   day_gap_after  label  user_id  coupon_id  date_received  \n",
       "0            0.0      0  1832624       7610       20160429  \n",
       "1            0.0      0   163606       5054       20160421  \n",
       "2            0.0      0    94107       7610       20160412  \n",
       "3            0.0      0  4061024       7610       20160426  \n",
       "4            0.0      0  4061024       9871       20160409  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f3特征\n",
    "traindf = train_f3.copy()\n",
    "\n",
    "#按日期分割，为了加快速度，只用了一般数据进行网格调参，正式的时候应该全用\n",
    "train = traindf[traindf.date_received < 20160515]\n",
    "test = traindf[traindf.date_received >= 20160515]\n",
    "\n",
    "train_data = get_predictors_df(train).copy()\n",
    "train_target = get_target_df(train).copy()\n",
    "test_data = get_predictors_df(test).copy()\n",
    "test_target = get_target_df(test).copy()\n",
    "\n",
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. learning_rate=0.1, n_estimators=100, total=   0.9s\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .............. learning_rate=0.1, n_estimators=100, total=   0.8s\n",
      "[CV] learning_rate=0.1, n_estimators=100 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=100, total=   0.9s\n",
      "[CV] learning_rate=0.1, n_estimators=150 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=150, total=   1.1s\n",
      "[CV] learning_rate=0.1, n_estimators=150 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=150, total=   1.0s\n",
      "[CV] learning_rate=0.1, n_estimators=150 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=150, total=   1.0s\n",
      "[CV] learning_rate=0.1, n_estimators=175 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=175, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=175 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=175, total=   1.5s\n",
      "[CV] learning_rate=0.1, n_estimators=175 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=175, total=   1.3s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=200, total=   1.7s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=200, total=   1.6s\n",
      "[CV] learning_rate=0.1, n_estimators=200 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=200, total=   1.7s\n",
      "[CV] learning_rate=0.1, n_estimators=225 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=225, total=   1.5s\n",
      "[CV] learning_rate=0.1, n_estimators=225 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=225, total=   1.5s\n",
      "[CV] learning_rate=0.1, n_estimators=225 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=225, total=   1.8s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=250, total=   1.9s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=250, total=   1.7s\n",
      "[CV] learning_rate=0.1, n_estimators=250 .............................\n",
      "[CV] .............. learning_rate=0.1, n_estimators=250, total=   2.2s\n",
      "[CV] learning_rate=0.05, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=100, total=   1.1s\n",
      "[CV] learning_rate=0.05, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=100, total=   1.0s\n",
      "[CV] learning_rate=0.05, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=100, total=   1.0s\n",
      "[CV] learning_rate=0.05, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=150, total=   1.2s\n",
      "[CV] learning_rate=0.05, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=150, total=   1.2s\n",
      "[CV] learning_rate=0.05, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=150, total=   1.3s\n",
      "[CV] learning_rate=0.05, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=175, total=   1.3s\n",
      "[CV] learning_rate=0.05, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=175, total=   1.3s\n",
      "[CV] learning_rate=0.05, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=175, total=   1.3s\n",
      "[CV] learning_rate=0.05, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=200, total=   1.5s\n",
      "[CV] learning_rate=0.05, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=200, total=   1.4s\n",
      "[CV] learning_rate=0.05, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=200, total=   1.7s\n",
      "[CV] learning_rate=0.05, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=225, total=   1.8s\n",
      "[CV] learning_rate=0.05, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=225, total=   1.8s\n",
      "[CV] learning_rate=0.05, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=225, total=   1.5s\n",
      "[CV] learning_rate=0.05, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=250, total=   1.8s\n",
      "[CV] learning_rate=0.05, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=250, total=   2.2s\n",
      "[CV] learning_rate=0.05, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.05, n_estimators=250, total=   1.9s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=100, total=   1.0s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=100, total=   0.9s\n",
      "[CV] learning_rate=0.01, n_estimators=100 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=100, total=   1.2s\n",
      "[CV] learning_rate=0.01, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=150, total=   1.8s\n",
      "[CV] learning_rate=0.01, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=150, total=   1.7s\n",
      "[CV] learning_rate=0.01, n_estimators=150 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=150, total=   1.7s\n",
      "[CV] learning_rate=0.01, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=175, total=   1.8s\n",
      "[CV] learning_rate=0.01, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=175, total=   1.7s\n",
      "[CV] learning_rate=0.01, n_estimators=175 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=175, total=   1.9s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=200, total=   1.7s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=200, total=   2.1s\n",
      "[CV] learning_rate=0.01, n_estimators=200 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=200, total=   1.7s\n",
      "[CV] learning_rate=0.01, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=225, total=   2.1s\n",
      "[CV] learning_rate=0.01, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=225, total=   1.8s\n",
      "[CV] learning_rate=0.01, n_estimators=225 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=225, total=   1.8s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=250, total=   2.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=250, total=   2.0s\n",
      "[CV] learning_rate=0.01, n_estimators=250 ............................\n",
      "[CV] ............. learning_rate=0.01, n_estimators=250, total=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.8199142525832528\n",
      "最优参数:\n",
      "{'learning_rate': 0.05, 'n_estimators': 250}\n"
     ]
    }
   ],
   "source": [
    "#第一步：学习率和迭代次数\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 切分数据 训练数据80% 验证数据20%\n",
    "# 为了加快速度CV选的3，其实一般用5\n",
    "# 因为每训练一次耗时很多，所以每个参数的选项不多，间隔比较大，正式的时候应该是比较多，间隔比较细的\n",
    "# 本次只是演示，所以如果最好参数位于区间的边缘也就直接用了，其实如果最好参数在边缘，需要重新再搜索。\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       max_depth=5,\n",
    "                       bagging_fraction=0.8,\n",
    "                       feature_fraction=0.8)\n",
    "parameters = {'n_estimators': [100, 150, 175, 200, 225, 250],'learning_rate': [0.1,0.05,0.01]}\n",
    "\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=2)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只是演示，实际中若取值为网格边缘应重新确定网格取值，这里确定学习率为0.05，迭代次数为250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 56 candidates, totalling 168 fits\n",
      "[CV] max_depth=4, num_leaves=10 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... max_depth=4, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=10 ......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... max_depth=4, num_leaves=10, total=   1.2s\n",
      "[CV] max_depth=4, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=10, total=   1.3s\n",
      "[CV] max_depth=4, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=20, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=20, total=   2.1s\n",
      "[CV] max_depth=4, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=20, total=   1.8s\n",
      "[CV] max_depth=4, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=30, total=   2.2s\n",
      "[CV] max_depth=4, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=30, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=30, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=40, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=40, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=40, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=50, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=50, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=50, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=60, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=60, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=60, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=70, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=70, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=70, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=80, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=80, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=80, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=90, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=90, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=4, num_leaves=90, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=100, total=   2.0s\n",
      "[CV] max_depth=4, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=100, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=100, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=110, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=110, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=110, total=   1.7s\n",
      "[CV] max_depth=4, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=120, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=120, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=120, total=   1.4s\n",
      "[CV] max_depth=4, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=130, total=   1.7s\n",
      "[CV] max_depth=4, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=130, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=130, total=   1.5s\n",
      "[CV] max_depth=4, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=140, total=   1.6s\n",
      "[CV] max_depth=4, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=140, total=   1.7s\n",
      "[CV] max_depth=4, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=4, num_leaves=140, total=   1.5s\n",
      "[CV] max_depth=5, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=10, total=   1.6s\n",
      "[CV] max_depth=5, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=10, total=   1.6s\n",
      "[CV] max_depth=5, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=10, total=   1.6s\n",
      "[CV] max_depth=5, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=20, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=20, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=20, total=   1.8s\n",
      "[CV] max_depth=5, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=30, total=   2.4s\n",
      "[CV] max_depth=5, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=30, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=30, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=40, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=40, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=40, total=   3.4s\n",
      "[CV] max_depth=5, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=50, total=   3.0s\n",
      "[CV] max_depth=5, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=50, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=50, total=   2.1s\n",
      "[CV] max_depth=5, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=60, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=60, total=   2.4s\n",
      "[CV] max_depth=5, num_leaves=60 ......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....................... max_depth=5, num_leaves=60, total=   1.8s\n",
      "[CV] max_depth=5, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=70, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=70, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=70, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=80, total=   2.3s\n",
      "[CV] max_depth=5, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=80, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=80, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=90, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=90, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=5, num_leaves=90, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=100, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=100, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=100, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=110, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=110, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=110, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=120, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=120, total=   1.6s\n",
      "[CV] max_depth=5, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=120, total=   1.8s\n",
      "[CV] max_depth=5, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=130, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=130, total=   2.0s\n",
      "[CV] max_depth=5, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=130, total=   1.9s\n",
      "[CV] max_depth=5, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=140, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=140, total=   1.7s\n",
      "[CV] max_depth=5, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=5, num_leaves=140, total=   1.7s\n",
      "[CV] max_depth=6, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=6, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=6, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=6, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=20, total=   1.7s\n",
      "[CV] max_depth=6, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=20, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=20, total=   1.7s\n",
      "[CV] max_depth=6, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=30, total=   1.8s\n",
      "[CV] max_depth=6, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=30, total=   1.8s\n",
      "[CV] max_depth=6, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=30, total=   1.8s\n",
      "[CV] max_depth=6, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=40, total=   2.3s\n",
      "[CV] max_depth=6, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=40, total=   2.4s\n",
      "[CV] max_depth=6, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=40, total=   2.4s\n",
      "[CV] max_depth=6, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=50, total=   3.1s\n",
      "[CV] max_depth=6, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=50, total=   2.7s\n",
      "[CV] max_depth=6, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=50, total=   2.6s\n",
      "[CV] max_depth=6, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=60, total=   2.6s\n",
      "[CV] max_depth=6, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=60, total=   2.5s\n",
      "[CV] max_depth=6, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=60, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=70, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=70, total=   1.9s\n",
      "[CV] max_depth=6, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=70, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=80, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=80, total=   2.2s\n",
      "[CV] max_depth=6, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=80, total=   2.5s\n",
      "[CV] max_depth=6, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=90, total=   2.3s\n",
      "[CV] max_depth=6, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=90, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=6, num_leaves=90, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=100, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=100, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=100, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=110, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=110, total=   2.2s\n",
      "[CV] max_depth=6, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=110, total=   2.3s\n",
      "[CV] max_depth=6, num_leaves=120 .....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...................... max_depth=6, num_leaves=120, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=120, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=120, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=130, total=   2.3s\n",
      "[CV] max_depth=6, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=130, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=130, total=   2.1s\n",
      "[CV] max_depth=6, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=140, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=140, total=   2.0s\n",
      "[CV] max_depth=6, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=6, num_leaves=140, total=   1.9s\n",
      "[CV] max_depth=7, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=10, total=   1.5s\n",
      "[CV] max_depth=7, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=7, num_leaves=10 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=10, total=   1.4s\n",
      "[CV] max_depth=7, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=20, total=   1.7s\n",
      "[CV] max_depth=7, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=20, total=   1.6s\n",
      "[CV] max_depth=7, num_leaves=20 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=20, total=   1.7s\n",
      "[CV] max_depth=7, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=30, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=30, total=   1.9s\n",
      "[CV] max_depth=7, num_leaves=30 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=30, total=   2.5s\n",
      "[CV] max_depth=7, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=40, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=40, total=   1.9s\n",
      "[CV] max_depth=7, num_leaves=40 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=40, total=   2.1s\n",
      "[CV] max_depth=7, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=50, total=   2.2s\n",
      "[CV] max_depth=7, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=50, total=   2.2s\n",
      "[CV] max_depth=7, num_leaves=50 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=50, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=60, total=   2.2s\n",
      "[CV] max_depth=7, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=60, total=   2.1s\n",
      "[CV] max_depth=7, num_leaves=60 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=60, total=   3.4s\n",
      "[CV] max_depth=7, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=70, total=   2.7s\n",
      "[CV] max_depth=7, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=70, total=   2.5s\n",
      "[CV] max_depth=7, num_leaves=70 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=70, total=   2.7s\n",
      "[CV] max_depth=7, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=80, total=   2.7s\n",
      "[CV] max_depth=7, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=80, total=   2.2s\n",
      "[CV] max_depth=7, num_leaves=80 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=80, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=90, total=   2.8s\n",
      "[CV] max_depth=7, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=90, total=   2.6s\n",
      "[CV] max_depth=7, num_leaves=90 ......................................\n",
      "[CV] ....................... max_depth=7, num_leaves=90, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=100, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=100, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=100 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=100, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=110, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=110, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=110 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=110, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=120, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=120, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=120 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=120, total=   2.2s\n",
      "[CV] max_depth=7, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=130, total=   2.6s\n",
      "[CV] max_depth=7, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=130, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=130 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=130, total=   2.3s\n",
      "[CV] max_depth=7, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=140, total=   2.4s\n",
      "[CV] max_depth=7, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=140, total=   2.9s\n",
      "[CV] max_depth=7, num_leaves=140 .....................................\n",
      "[CV] ...................... max_depth=7, num_leaves=140, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 168 out of 168 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.8210744265607519\n",
      "最优参数:\n",
      "{'max_depth': 7, 'num_leaves': 100}\n"
     ]
    }
   ],
   "source": [
    "#第二步：确定max_depth和num_leaves\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       learning_rate=0.05,\n",
    "                       bagging_fraction=0.8,\n",
    "                       feature_fraction=0.8)\n",
    "parameters = {'max_depth': range(4, 8, 1), 'num_leaves': range(10, 150, 10)}\n",
    "#parameters={'max_depth': range(4,8,2), 'num_leaves':range(10, 100, 20)}\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=2)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] max_bin=100, min_data_in_leaf=100 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... max_bin=100, min_data_in_leaf=100, score=0.952, total=   2.0s\n",
      "[CV] max_bin=100, min_data_in_leaf=100 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... max_bin=100, min_data_in_leaf=100, score=0.951, total=   2.0s\n",
      "[CV] max_bin=100, min_data_in_leaf=100 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... max_bin=100, min_data_in_leaf=100, score=0.952, total=   2.1s\n",
      "[CV] max_bin=200, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=200, min_data_in_leaf=100, score=0.952, total=   2.5s\n",
      "[CV] max_bin=200, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=200, min_data_in_leaf=100, score=0.951, total=   2.2s\n",
      "[CV] max_bin=200, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=200, min_data_in_leaf=100, score=0.952, total=   2.5s\n",
      "[CV] max_bin=300, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=300, min_data_in_leaf=100, score=0.953, total=   2.5s\n",
      "[CV] max_bin=300, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=300, min_data_in_leaf=100, score=0.951, total=   2.7s\n",
      "[CV] max_bin=300, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=300, min_data_in_leaf=100, score=0.952, total=   2.3s\n",
      "[CV] max_bin=400, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=400, min_data_in_leaf=100, score=0.953, total=   2.4s\n",
      "[CV] max_bin=400, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=400, min_data_in_leaf=100, score=0.951, total=   2.0s\n",
      "[CV] max_bin=400, min_data_in_leaf=100 ...............................\n",
      "[CV] ... max_bin=400, min_data_in_leaf=100, score=0.952, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.827158271564898\n",
      "最优参数:\n",
      "{'max_bin': 300, 'min_data_in_leaf': 100}\n"
     ]
    }
   ],
   "source": [
    "#第三步：确定min_data_in_leaf和max_bin in\n",
    "#已经确认内容：\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "#{'max_depth': 7, 'num_leaves': 100}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       learning_rate=0.05,\n",
    "                       bagging_fraction=0.8,\n",
    "                       feature_fraction=0.8)\n",
    "\n",
    "#parameters={'max_bin': range(100,500,50),'min_data_in_leaf':range(100,150,10)}\n",
    "parameters = {\n",
    "    'max_bin': range(100, 500, 100),\n",
    "    'min_data_in_leaf': range(100, 150, 50)\n",
    "}\n",
    "#调高 verbose可以看到更多信息\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=3)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 125 candidates, totalling 375 fits\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6, score=0.950, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7, score=0.951, total=   2.9s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8, score=0.953, total=   3.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8, score=0.951, total=   7.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.8, score=0.952, total=  10.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   8.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9, score=0.951, total=   8.8s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   8.8s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0, score=0.952, total=   8.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   7.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   6.0s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6, score=0.953, total=   2.9s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   3.8s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7, score=0.953, total=   2.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.7, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8, score=0.953, total=   2.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   4.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9, score=0.953, total=   3.0s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0, score=0.953, total=   2.8s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   3.0s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   3.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6, score=0.953, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.6, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8, score=0.953, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.8, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9, score=0.953, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   4.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0, score=0.953, total=   4.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   3.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6, score=0.953, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7, score=0.953, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9, score=0.953, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=0.9, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0, score=0.953, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6, score=0.953, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7, score=0.953, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8, score=0.953, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9, score=0.953, total=   2.9s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=0.9, score=0.951, total=   3.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0, score=0.953, total=   2.5s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.6, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6, score=0.950, total=   1.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8, score=0.953, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8, score=0.951, total=   2.8s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.8, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   4.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6, score=0.953, total=   3.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7, score=0.950, total=   2.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.7, score=0.952, total=   4.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8, score=0.952, total=   3.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   3.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.8, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9, score=0.953, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=0.9, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0, score=0.953, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   3.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7, score=0.953, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.8, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   2.5s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   2.8s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   3.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.7s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   3.5s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6, score=0.953, total=   7.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6, score=0.951, total=   8.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   8.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   8.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   8.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   7.9s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8, score=0.952, total=   8.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   8.1s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.8, score=0.952, total=   6.0s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   3.6s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9, score=0.951, total=   2.8s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0, score=0.953, total=   2.4s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.7, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6, score=0.950, total=   1.8s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8, score=0.953, total=   2.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.8, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9, score=0.951, total=   2.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   7.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=0, feature_fraction=1.0, score=0.951, total=  10.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6, score=0.953, total=  12.7s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   9.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.6, score=0.952, total=  10.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7, score=0.953, total=  10.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7, score=0.951, total=  10.6s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.7, score=0.952, total=  11.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8, score=0.953, total=  10.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.8, score=0.952, total=   6.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9, score=0.953, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   6.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=0.9, score=0.952, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0, score=0.953, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   6.5s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6, score=0.953, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6, score=0.951, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7, score=0.953, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7, score=0.950, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8, score=0.953, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   6.8s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6, score=0.953, total=   6.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7, score=0.953, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   6.4s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6, score=0.953, total=   5.8s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6, score=0.950, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   5.8s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8, score=0.953, total=   5.9s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   6.1s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9, score=0.951, total=   7.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   6.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0, score=0.952, total=   6.0s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.8, bagging_freq=8, feature_fraction=1.0, score=0.952, total=   6.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   5.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6, score=0.950, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   5.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   5.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7, score=0.951, total=   5.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   5.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8, score=0.953, total=   5.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8, score=0.951, total=   5.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.8, score=0.952, total=   5.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   5.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9, score=0.951, total=   5.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   5.7s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0, score=0.952, total=   5.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   5.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   5.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6, score=0.953, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.6, score=0.952, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7, score=0.953, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7, score=0.951, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.7, score=0.952, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8, score=0.953, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   7.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.8, score=0.952, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9, score=0.953, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=0.9, score=0.952, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0, score=0.953, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   6.7s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=2, feature_fraction=1.0, score=0.952, total=   6.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6, score=0.953, total=   6.0s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7, score=0.953, total=   6.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8, score=0.953, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   6.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.8, score=0.952, total=   6.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   6.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   6.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   6.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   6.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6, score=0.951, total=   6.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   6.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8, score=0.953, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8, score=0.951, total=   6.2s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   6.1s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   5.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9, score=0.951, total=   2.8s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6, score=0.953, total=   2.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6, score=0.951, total=   2.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7, score=0.953, total=   2.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   2.4s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8, score=0.953, total=   2.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.8, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9, score=0.953, total=   2.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   2.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0, score=0.952, total=   2.6s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.5s\n",
      "[CV] bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=0.9, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.6s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6, score=0.950, total=   2.5s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.6, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   2.7s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7, score=0.951, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8, score=0.953, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.8, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=0.9, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=0, feature_fraction=1.0, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6, score=0.950, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7, score=0.951, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8, score=0.953, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.8, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=0.9, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=2, feature_fraction=1.0, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6, score=0.950, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7, score=0.951, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8, score=0.953, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.8, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=0.9, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=4, feature_fraction=1.0, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6, score=0.950, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7, score=0.951, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8, score=0.953, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8 ......\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.8, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=0.9, score=0.952, total=   2.3s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=6, feature_fraction=1.0, score=0.951, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6, score=0.950, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.6, score=0.952, total=   1.8s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7, score=0.951, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.7, score=0.952, total=   1.9s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8, score=0.953, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.8, score=0.952, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9, score=0.951, total=   2.0s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=0.9, score=0.952, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0, score=0.952, total=   2.1s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.2s\n",
      "[CV] bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0 ......\n",
      "[CV]  bagging_fraction=1.0, bagging_freq=8, feature_fraction=1.0, score=0.951, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 375 out of 375 | elapsed: 24.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.8254940593505994\n",
      "最优参数:\n",
      "{'bagging_fraction': 0.9, 'bagging_freq': 8, 'feature_fraction': 0.9}\n"
     ]
    }
   ],
   "source": [
    "#第四步：确定feature_fraction、bagging_fraction、bagging_freq\n",
    "#已经确认内容：\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "#{'max_depth': 7, 'num_leaves': 100}\n",
    "#{'max_bin': 300, 'min_data_in_leaf': 100}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.05,\n",
    "                       bagging_fraction=0.8,\n",
    "                       feature_fraction=0.8)\n",
    "\n",
    "parameters = {\n",
    "    'feature_fraction': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'bagging_fraction': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'bagging_freq': range(0, 10, 2)\n",
    "}\n",
    "\n",
    "#调高 verbose可以看到更多信息\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=3)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1e-05 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... lambda_l1=1e-05, lambda_l2=1e-05, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1e-05 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... lambda_l1=1e-05, lambda_l2=1e-05, score=0.951, total=   3.2s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1e-05 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... lambda_l1=1e-05, lambda_l2=1e-05, score=0.952, total=   3.9s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=1e-05, lambda_l2=0.001, score=0.953, total=   3.1s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=1e-05, lambda_l2=0.001, score=0.951, total=   3.4s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=1e-05, lambda_l2=0.001, score=0.952, total=   4.8s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.953, total=   3.1s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.952, total=   2.8s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.0, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.1, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.3, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.3, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.5, score=0.953, total=   2.7s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.5, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.5, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.7, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.7, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.9, score=0.953, total=   2.7s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.9, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=0.9, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=1.0, score=0.953, total=   2.7s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=1.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1e-05, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=1e-05, lambda_l2=1.0, score=0.951, total=   2.8s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1e-05 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=1e-05, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1e-05 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=1e-05, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1e-05 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=1e-05, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=0.001, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=0.001, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.001 ................................\n",
      "[CV] .... lambda_l1=0.001, lambda_l2=0.001, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.0, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.1 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.1, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.3, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.3, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.3 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.3, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.5, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.5 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.5, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.7, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.7 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.9, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=0.9 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=0.9, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=1.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.001, lambda_l2=1.0 ..................................\n",
      "[CV] ...... lambda_l1=0.001, lambda_l2=1.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.951, total=   3.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.952, total=   3.7s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.952, total=   5.0s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.951, total=   6.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.952, total=   6.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   6.3s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.953, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.952, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.953, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.951, total=   6.0s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.953, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.953, total=   6.1s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=1e-05, score=0.953, total=   6.3s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=1e-05, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=1e-05, score=0.952, total=   6.4s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=0.001, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=0.001, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.0, lambda_l2=0.001, score=0.952, total=   6.3s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.951, total=   6.8s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.952, total=   6.5s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.0, score=0.953, total=   6.4s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.0, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.0, score=0.952, total=   6.3s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.1, score=0.952, total=   6.3s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.3, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.3, score=0.951, total=   6.3s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.3, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.5, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.5, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.5, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.7, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.7, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.7, score=0.951, total=   6.1s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.9, score=0.953, total=   6.1s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.9, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=0.9, score=0.951, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=1.0, score=0.953, total=   6.2s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1.0 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ lambda_l1=0.0, lambda_l2=1.0, score=0.951, total=   2.8s\n",
      "[CV] lambda_l1=0.0, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.0, lambda_l2=1.0, score=0.951, total=   2.9s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=1e-05, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.1, lambda_l2=0.001, score=0.952, total=   3.2s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.953, total=   3.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.0, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.951, total=   2.4s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.1, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.1, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=1e-05, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=1e-05, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=1e-05, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=0.001, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=0.001, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.3, lambda_l2=0.001, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.0, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.3, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.3, score=0.950, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.3, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.5, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.5, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.5, score=0.952, total=   2.8s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.7, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.9, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=0.9 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ lambda_l1=0.3, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=1.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=1.0, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=0.3, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.3, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=1e-05, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=1e-05, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=1e-05, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=0.001, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=0.001, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.5, lambda_l2=0.001, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.0, score=0.953, total=   2.9s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.0, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.3, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.3, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.5, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.7, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.7, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.9, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=1.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.5, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.5, lambda_l2=1.0, score=0.951, total=   2.7s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=1e-05, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=1e-05, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=1e-05, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=0.001, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=0.001, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.7, lambda_l2=0.001, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.0, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.3, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.3, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.5, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.7, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.7, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.9 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.9, score=0.954, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=1.0, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.7, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.7, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=1e-05, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=1e-05, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=1e-05, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=0.001, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=0.001, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=0.9, lambda_l2=0.001, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.0, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.0, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.0, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.1, score=0.952, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.3, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.3, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.5, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.5, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.7, score=0.953, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.9, score=0.953, total=   3.6s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.9, score=0.951, total=   3.3s\n",
      "[CV] lambda_l1=0.9, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=0.9, score=0.951, total=   3.7s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=1.0, score=0.953, total=   3.0s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=0.9, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=0.9, lambda_l2=1.0, score=0.951, total=   2.8s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=1e-05, score=0.953, total=   2.9s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=1e-05, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1e-05 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=1e-05, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=0.001, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=0.001, score=0.951, total=   3.1s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.001 ..................................\n",
      "[CV] ...... lambda_l1=1.0, lambda_l2=0.001, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.0, score=0.952, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.1 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.1, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.3, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.3, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.3 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.3, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.5, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.5, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.5 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.5, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.7, score=0.953, total=   2.7s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.7 ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.7, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.7 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.7, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.9, score=0.953, total=   2.7s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.9, score=0.951, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=0.9 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=0.9, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=1.0, score=0.953, total=   2.6s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=1.0, score=0.951, total=   2.5s\n",
      "[CV] lambda_l1=1.0, lambda_l2=1.0 ....................................\n",
      "[CV] ........ lambda_l1=1.0, lambda_l2=1.0, score=0.951, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 300 out of 300 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.825493004351614\n",
      "最优参数:\n",
      "{'lambda_l1': 0.0, 'lambda_l2': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "#第五步：确定lambda_l1和lambda_l2\n",
    "#已经确认内容：\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "#{'max_depth': 7, 'num_leaves': 100}\n",
    "#{'max_bin': 300, 'min_data_in_leaf': 100}\n",
    "#{'bagging_fraction': 0.9, 'bagging_freq': 8, 'feature_fraction': 0.9}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.05,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "parameters = {\n",
    "    'lambda_l1': [1e-5, 1e-3, 1e-1, 0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "    'lambda_l2': [1e-5, 1e-3, 1e-1, 0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "#调高 verbose可以看到更多信息\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=3)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "[CV] min_split_gain=0.0 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. min_split_gain=0.0, score=0.953, total=   2.4s\n",
      "[CV] min_split_gain=0.0 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. min_split_gain=0.0, score=0.951, total=   2.2s\n",
      "[CV] min_split_gain=0.0 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. min_split_gain=0.0, score=0.952, total=   2.4s\n",
      "[CV] min_split_gain=0.1 ..............................................\n",
      "[CV] .................. min_split_gain=0.1, score=0.952, total=   2.6s\n",
      "[CV] min_split_gain=0.1 ..............................................\n",
      "[CV] .................. min_split_gain=0.1, score=0.951, total=   2.6s\n",
      "[CV] min_split_gain=0.1 ..............................................\n",
      "[CV] .................. min_split_gain=0.1, score=0.951, total=   2.5s\n",
      "[CV] min_split_gain=0.2 ..............................................\n",
      "[CV] .................. min_split_gain=0.2, score=0.953, total=   2.5s\n",
      "[CV] min_split_gain=0.2 ..............................................\n",
      "[CV] .................. min_split_gain=0.2, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.2 ..............................................\n",
      "[CV] .................. min_split_gain=0.2, score=0.952, total=   2.5s\n",
      "[CV] min_split_gain=0.3 ..............................................\n",
      "[CV] .................. min_split_gain=0.3, score=0.953, total=   2.5s\n",
      "[CV] min_split_gain=0.3 ..............................................\n",
      "[CV] .................. min_split_gain=0.3, score=0.951, total=   2.5s\n",
      "[CV] min_split_gain=0.3 ..............................................\n",
      "[CV] .................. min_split_gain=0.3, score=0.952, total=   2.5s\n",
      "[CV] min_split_gain=0.4 ..............................................\n",
      "[CV] .................. min_split_gain=0.4, score=0.953, total=   2.5s\n",
      "[CV] min_split_gain=0.4 ..............................................\n",
      "[CV] .................. min_split_gain=0.4, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.4 ..............................................\n",
      "[CV] .................. min_split_gain=0.4, score=0.952, total=   2.5s\n",
      "[CV] min_split_gain=0.5 ..............................................\n",
      "[CV] .................. min_split_gain=0.5, score=0.953, total=   2.4s\n",
      "[CV] min_split_gain=0.5 ..............................................\n",
      "[CV] .................. min_split_gain=0.5, score=0.951, total=   2.5s\n",
      "[CV] min_split_gain=0.5 ..............................................\n",
      "[CV] .................. min_split_gain=0.5, score=0.952, total=   2.4s\n",
      "[CV] min_split_gain=0.6 ..............................................\n",
      "[CV] .................. min_split_gain=0.6, score=0.953, total=   2.5s\n",
      "[CV] min_split_gain=0.6 ..............................................\n",
      "[CV] .................. min_split_gain=0.6, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.6 ..............................................\n",
      "[CV] .................. min_split_gain=0.6, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.7 ..............................................\n",
      "[CV] .................. min_split_gain=0.7, score=0.953, total=   2.4s\n",
      "[CV] min_split_gain=0.7 ..............................................\n",
      "[CV] .................. min_split_gain=0.7, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.7 ..............................................\n",
      "[CV] .................. min_split_gain=0.7, score=0.952, total=   2.5s\n",
      "[CV] min_split_gain=0.8 ..............................................\n",
      "[CV] .................. min_split_gain=0.8, score=0.953, total=   2.4s\n",
      "[CV] min_split_gain=0.8 ..............................................\n",
      "[CV] .................. min_split_gain=0.8, score=0.951, total=   2.3s\n",
      "[CV] min_split_gain=0.8 ..............................................\n",
      "[CV] .................. min_split_gain=0.8, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=0.9 ..............................................\n",
      "[CV] .................. min_split_gain=0.9, score=0.953, total=   2.3s\n",
      "[CV] min_split_gain=0.9 ..............................................\n",
      "[CV] .................. min_split_gain=0.9, score=0.951, total=   2.3s\n",
      "[CV] min_split_gain=0.9 ..............................................\n",
      "[CV] .................. min_split_gain=0.9, score=0.952, total=   2.3s\n",
      "[CV] min_split_gain=1.0 ..............................................\n",
      "[CV] .................. min_split_gain=1.0, score=0.953, total=   2.2s\n",
      "[CV] min_split_gain=1.0 ..............................................\n",
      "[CV] .................. min_split_gain=1.0, score=0.951, total=   2.4s\n",
      "[CV] min_split_gain=1.0 ..............................................\n",
      "[CV] .................. min_split_gain=1.0, score=0.952, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM GridSearchCV AUC Score:    0.825493004351614\n",
      "最优参数:\n",
      "{'min_split_gain': 0.0}\n"
     ]
    }
   ],
   "source": [
    "#第六步：确定 min_split_gain\n",
    "#已经确认内容：\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "#{'max_depth': 7, 'num_leaves': 100}\n",
    "#{'max_bin': 300, 'min_data_in_leaf': 100}\n",
    "#{'bagging_fraction': 0.9, 'bagging_freq': 8, 'feature_fraction': 0.9}\n",
    "#{'lambda_l1': 0.0, 'lambda_l2': 1e-05}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.05,\n",
    "                       lambda_l1=0.0,\n",
    "                       lambda_l2=1e-05,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "parameters = {\n",
    "    'min_split_gain': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "#调高 verbose可以看到更多信息\n",
    "clf = GridSearchCV(model, parameters, cv=3, verbose=3)\n",
    "clf.fit(train_data, train_target)\n",
    "\n",
    "score_test = roc_auc_score(test_target, clf.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM GridSearchCV AUC Score:   \", score_test)\n",
    "print(\"最优参数:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM learning rate 0.1 AUC Score:    0.8046725120742325\n",
      "LightGBM learning rate 0.05 AUC Score:    0.825493004351614\n",
      "LightGBM learning rate 0.01 AUC Score:    0.8298804969022311\n",
      "LightGBM learning rate 0.005 AUC Score:    0.8214530365963739\n"
     ]
    }
   ],
   "source": [
    "# 第七步：改变学习率或迭代次数，验证模型\n",
    "#已经确认内容：\n",
    "#{'n_estimators':250, 'learning_rate':0.05}\n",
    "#{'max_depth': 7, 'num_leaves': 100}\n",
    "#{'max_bin': 300, 'min_data_in_leaf': 100}\n",
    "#{'bagging_fraction': 0.9, 'bagging_freq': 8, 'feature_fraction': 0.9}\n",
    "#{'lambda_l1': 0.0, 'lambda_l2': 1e-05}\n",
    "#{'min_split_gain': 0.0}\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.1,\n",
    "                       lambda_l1=0.0,\n",
    "                       lambda_l2=1e-05,\n",
    "                       min_split_gain=0.0,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "model.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, model.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM learning rate 0.1 AUC Score:   \", score_test)\n",
    "\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.05,\n",
    "                       lambda_l1=0.0,\n",
    "                       lambda_l2=1e-05,\n",
    "                       min_split_gain=0.0,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "model.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, model.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM learning rate 0.05 AUC Score:   \", score_test)\n",
    "\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.01,\n",
    "                       lambda_l1=0.0,\n",
    "                       lambda_l2=1e-05,\n",
    "                       min_split_gain=0.0,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "model.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, model.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM learning rate 0.01 AUC Score:   \", score_test)\n",
    "\n",
    "model = LGBMClassifier(boosting_type='gbdt',\n",
    "                       objective='binary',\n",
    "                       metrics='auc',\n",
    "                       n_estimators=250,\n",
    "                       max_depth=7,\n",
    "                       num_leaves=100,\n",
    "                       max_bin=300,\n",
    "                       min_data_in_leaf=100,\n",
    "                       learning_rate=0.005,\n",
    "                       lambda_l1=0.0,\n",
    "                       lambda_l2=1e-05,\n",
    "                       min_split_gain=0.0,\n",
    "                       bagging_freq=8,\n",
    "                       bagging_fraction=0.9,\n",
    "                       feature_fraction=0.9)\n",
    "\n",
    "model.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, model.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"LightGBM learning rate 0.005 AUC Score:   \", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述发现学习率为0.01的AUC效果优于0.05，也即参数验证有误，理论上需要重新调参优化，但这里.01较.05提升不明显，省略掉重新调参直接取学习为0.01。\n",
    "\n",
    "最终的最优参数为：\n",
    "model = LGBMClassifier(<br/>\n",
    "boosting_type='gbdt',<br/>\n",
    "objective='binary',<br/>\n",
    "metrics='auc',<br/>\n",
    "n_estimators=200, learning_rate=0.01, <br/>\n",
    "max_depth=7, num_leaves=100,  <br/>\n",
    "max_bin=300, min_data_in_leaf=100,    <br/>\n",
    "lambda_l1=0.0, lambda_l2=1e-05,<br/>\n",
    "bagging_freq=8, bagging_fraction=0.9,feature_fraction=0.9,<br/>\n",
    "min_split_gain=0.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认参数 AUC Score:    0.8258363368655586\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier()\n",
    "\n",
    "model.fit(train_data, train_target)\n",
    "score_test = roc_auc_score(test_target, model.predict_proba(test_data)[:, 1])\n",
    "\n",
    "print(\"默认参数 AUC Score:   \", score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认参数\n",
      "LGB总体AUC: [0.8747, 0.8741, 0.8476, 0.8409, 0.8435]\n",
      "LGBCoupon AUC: [0.6357, 0.5926, 0.6031, 0.6113, 0.6068]\n",
      "调参后\n",
      "LGB总体AUC: [0.8698, 0.8671, 0.8429, 0.835, 0.8368]\n",
      "LGBCoupon AUC: [0.641, 0.6019, 0.6042, 0.614, 0.6048]\n"
     ]
    }
   ],
   "source": [
    "#f3特征\n",
    "train = train_f2.copy()\n",
    "train.head()\n",
    "print('默认参数')\n",
    "classifier_df_score(train, 'LGB', 5)\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'eval_metric': 'auc',\n",
    "    'n_estimators': 200,\n",
    "    'max_depth': 7,\n",
    "    'num_leaves': 100,\n",
    "    'max_bin': 300,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.01,\n",
    "    'lambda_l1': 0.0,\n",
    "    'lambda_l2': 1e-05,\n",
    "    'min_split_gain': 0.0,\n",
    "    'bagging_freq': 8,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'feature_fraction': 0.9,\n",
    "    'seed': 42,\n",
    "    'n_thread': 12\n",
    "}\n",
    "print('调参后')\n",
    "classifier_df_score(train, 'LGB', 5, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比发现调参后的结果比默认参数有所提高，不过不是高很多，比不上特征对结果的影响。而且因为调参只能再测试集上作，有的时候调参造成过拟，调参后线上成绩可能反而会下降。所以调参一般都是在比赛后期再做，前期主要是特征和模型的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制验证曲线\n",
    "可以通过绘制验证曲线，可视化的了解调参的过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对进行网格调参\n",
    "def grid_plot(train_feat,\n",
    "              classifier,\n",
    "              cvnum,\n",
    "              param_range,\n",
    "              param_name,\n",
    "              param=None):\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    train_scores, test_scores = validation_curve(get_sklearn_model(classifier, param),\n",
    "                                                 get_predictors_df(train_feat),\n",
    "                                                 get_target_df(train_feat),\n",
    "                                                 param_name=param_name,\n",
    "                                                 param_range=param_range,\n",
    "                                                 cv=cvnum,\n",
    "                                                 scoring='roc_auc',\n",
    "                                                 n_jobs=1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.title(\"Validation Curve with \" + param_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.ylim(0.0, 1.1)\n",
    "    plt.semilogx(param_range,\n",
    "                 train_scores_mean,\n",
    "                 label=\"Training score\",\n",
    "                 color=\"r\")\n",
    "    plt.fill_between(param_range,\n",
    "                     train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std,\n",
    "                     alpha=0.2,\n",
    "                     color=\"r\")\n",
    "    plt.semilogx(param_range,\n",
    "                 test_scores_mean,\n",
    "                 label=\"Cross-validation score\",\n",
    "                 color=\"g\")\n",
    "    plt.fill_between(param_range,\n",
    "                     test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std,\n",
    "                     alpha=0.2,\n",
    "                     color=\"g\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#对逻辑回归的max_iter情况进行查看\n",
    "train_feat = train_f3.copy()\n",
    "#grid_plot(train_feat,classifier,3,[10,20,40,80,200,400,800],'n_estimators',param=params)\n",
    "grid_plot(train_feat,\n",
    "          'LR',\n",
    "          3, [1, 2, 5, 10, 20, 40, 50],\n",
    "          'max_iter',\n",
    "          param=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'sub_feature': 0.6,\n",
    "    'num_leaves': 50,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'feature_fraction': 0.8\n",
    "}\n",
    "train_feat = train_f3.copy()\n",
    "#grid_plot(train_feat,classifier,3,[10,20,40,80,200,400,800],'n_estimators',param=params)\n",
    "grid_plot(train_feat, 'LGB', 3, [10, 20, 40], 'n_estimators', param=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 10\n",
    "}\n",
    "train_feat = train_f3.copy()\n",
    "#grid_plot(train_feat,classifier,3,[10,20,40,80,200,400,800],'n_estimators',param=params)\n",
    "grid_plot(train_feat,\n",
    "          'LGB',\n",
    "          3, [0.1, 0.2, 0.5, 0.7, 0.8],\n",
    "          'colsample_bytree',\n",
    "          param=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
